{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04c5e2bc",
   "metadata": {},
   "source": [
    "Get community building samples from euss and renormalize the sample weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60acb568",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb12f4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "community = 'duluth' # TODO change community name\n",
    "Total_dwelling_unit_count = 39762  # TODO supplied by the community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3b65fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ylou2\\AppData\\Local\\Temp\\1\\ipykernel_18844\\646658200.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  community_up01['sample_weight'] = building_id_weight['sample_weight']*Total_dwelling_unit_count/building_id_weight['sample_weight'].sum()\n",
      "C:\\Users\\ylou2\\AppData\\Local\\Temp\\1\\ipykernel_18844\\646658200.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  community_up02['sample_weight'] = building_id_weight['sample_weight']*Total_dwelling_unit_count/building_id_weight['sample_weight'].sum()\n",
      "C:\\Users\\ylou2\\AppData\\Local\\Temp\\1\\ipykernel_18844\\646658200.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  community_up03['sample_weight'] = building_id_weight['sample_weight']*Total_dwelling_unit_count/building_id_weight['sample_weight'].sum()\n",
      "C:\\Users\\ylou2\\AppData\\Local\\Temp\\1\\ipykernel_18844\\646658200.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  community_up04['sample_weight'] = building_id_weight['sample_weight']*Total_dwelling_unit_count/building_id_weight['sample_weight'].sum()\n",
      "C:\\Users\\ylou2\\AppData\\Local\\Temp\\1\\ipykernel_18844\\646658200.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  community_up05['sample_weight'] = building_id_weight['sample_weight']*Total_dwelling_unit_count/building_id_weight['sample_weight'].sum()\n",
      "C:\\Users\\ylou2\\AppData\\Local\\Temp\\1\\ipykernel_18844\\646658200.py:44: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  community_up06['sample_weight'] = building_id_weight['sample_weight']*Total_dwelling_unit_count/building_id_weight['sample_weight'].sum()\n",
      "C:\\Users\\ylou2\\AppData\\Local\\Temp\\1\\ipykernel_18844\\646658200.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  community_up07['sample_weight'] = building_id_weight['sample_weight']*Total_dwelling_unit_count/building_id_weight['sample_weight'].sum()\n",
      "C:\\Users\\ylou2\\AppData\\Local\\Temp\\1\\ipykernel_18844\\646658200.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  community_up08['sample_weight'] = building_id_weight['sample_weight']*Total_dwelling_unit_count/building_id_weight['sample_weight'].sum()\n",
      "C:\\Users\\ylou2\\AppData\\Local\\Temp\\1\\ipykernel_18844\\646658200.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  community_up09['sample_weight'] = building_id_weight['sample_weight']*Total_dwelling_unit_count/building_id_weight['sample_weight'].sum()\n",
      "C:\\Users\\ylou2\\AppData\\Local\\Temp\\1\\ipykernel_18844\\646658200.py:68: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  community_up10['sample_weight'] = building_id_weight['sample_weight']*Total_dwelling_unit_count/building_id_weight['sample_weight'].sum()\n"
     ]
    }
   ],
   "source": [
    "building_id_weight = pd.read_csv(f'data_/downsampled_buildings_id/euss1_2018_results_up00__downsampled_method1__{community}.csv') # TODO change community name duluth\n",
    "building_id = building_id_weight['building_id']\n",
    "building_id_weight = building_id_weight.set_index('building_id')\n",
    "\n",
    "euss_up00 = pd.read_parquet('data_/euss_res_final_2018_550k_20220901/results_up00.parquet', engine='pyarrow')\n",
    "community_up00 = euss_up00.loc[euss_up00['building_id'].isin(building_id)]\n",
    "community_up00 = community_up00.set_index('building_id')\n",
    "community_up00['sample_weight'] = building_id_weight['sample_weight']*Total_dwelling_unit_count/building_id_weight['sample_weight'].sum()\n",
    "community_up00.to_csv(f'data_/community_building_samples/{community}/up00.csv')\n",
    "\n",
    "euss_up01 = pd.read_parquet('data_/euss_res_final_2018_550k_20220901/results_up01.parquet', engine='pyarrow')\n",
    "community_up01 = euss_up01.loc[euss_up01['building_id'].isin(building_id)]\n",
    "community_up01 = community_up01.set_index('building_id')\n",
    "community_up01['sample_weight'] = building_id_weight['sample_weight']*Total_dwelling_unit_count/building_id_weight['sample_weight'].sum()\n",
    "community_up01.to_csv(f'data_/community_building_samples/{community}/up01.csv')\n",
    "\n",
    "euss_up02 = pd.read_parquet('data_/euss_res_final_2018_550k_20220901/results_up02.parquet', engine='pyarrow')\n",
    "community_up02 = euss_up02.loc[euss_up02['building_id'].isin(building_id)]\n",
    "community_up02 = community_up02.set_index('building_id')\n",
    "community_up02['sample_weight'] = building_id_weight['sample_weight']*Total_dwelling_unit_count/building_id_weight['sample_weight'].sum()\n",
    "community_up02.to_csv(f'data_/community_building_samples/{community}/up02.csv')\n",
    "\n",
    "euss_up03 = pd.read_parquet('data_/euss_res_final_2018_550k_20220901/results_up03.parquet', engine='pyarrow')\n",
    "community_up03 = euss_up03.loc[euss_up03['building_id'].isin(building_id)]\n",
    "community_up03 = community_up03.set_index('building_id')\n",
    "community_up03['sample_weight'] = building_id_weight['sample_weight']*Total_dwelling_unit_count/building_id_weight['sample_weight'].sum()\n",
    "community_up03.to_csv(f'data_/community_building_samples/{community}/up03.csv')\n",
    "\n",
    "euss_up04 = pd.read_parquet('data_/euss_res_final_2018_550k_20220901/results_up04.parquet', engine='pyarrow')\n",
    "community_up04 = euss_up04.loc[euss_up04['building_id'].isin(building_id)]\n",
    "community_up04 = community_up04.set_index('building_id')\n",
    "community_up04['sample_weight'] = building_id_weight['sample_weight']*Total_dwelling_unit_count/building_id_weight['sample_weight'].sum()\n",
    "community_up04.to_csv(f'data_/community_building_samples/{community}/up04.csv')\n",
    "\n",
    "euss_up05 = pd.read_parquet('data_/euss_res_final_2018_550k_20220901/results_up05.parquet', engine='pyarrow')\n",
    "community_up05 = euss_up05.loc[euss_up05['building_id'].isin(building_id)]\n",
    "community_up05 = community_up05.set_index('building_id')\n",
    "community_up05['sample_weight'] = building_id_weight['sample_weight']*Total_dwelling_unit_count/building_id_weight['sample_weight'].sum()\n",
    "community_up05.to_csv(f'data_/community_building_samples/{community}/up05.csv')\n",
    "\n",
    "euss_up06 = pd.read_parquet('data_/euss_res_final_2018_550k_20220901/results_up06.parquet', engine='pyarrow')\n",
    "community_up06 = euss_up06.loc[euss_up06['building_id'].isin(building_id)]\n",
    "community_up06 = community_up06.set_index('building_id')\n",
    "community_up06['sample_weight'] = building_id_weight['sample_weight']*Total_dwelling_unit_count/building_id_weight['sample_weight'].sum()\n",
    "community_up06.to_csv(f'data_/community_building_samples/{community}/up06.csv')\n",
    "\n",
    "euss_up07 = pd.read_parquet('data_/euss_res_final_2018_550k_20220901/results_up07.parquet', engine='pyarrow')\n",
    "community_up07 = euss_up07.loc[euss_up07['building_id'].isin(building_id)]\n",
    "community_up07 = community_up07.set_index('building_id')\n",
    "community_up07['sample_weight'] = building_id_weight['sample_weight']*Total_dwelling_unit_count/building_id_weight['sample_weight'].sum()\n",
    "community_up07.to_csv(f'data_/community_building_samples/{community}/up07.csv')\n",
    "\n",
    "euss_up08 = pd.read_parquet('data_/euss_res_final_2018_550k_20220901/results_up08.parquet', engine='pyarrow')\n",
    "community_up08 = euss_up08.loc[euss_up08['building_id'].isin(building_id)]\n",
    "community_up08 = community_up08.set_index('building_id')\n",
    "community_up08['sample_weight'] = building_id_weight['sample_weight']*Total_dwelling_unit_count/building_id_weight['sample_weight'].sum()\n",
    "community_up08.to_csv(f'data_/community_building_samples/{community}/up08.csv')\n",
    "\n",
    "euss_up09 = pd.read_parquet('data_/euss_res_final_2018_550k_20220901/results_up09.parquet', engine='pyarrow')\n",
    "community_up09 = euss_up09.loc[euss_up09['building_id'].isin(building_id)]\n",
    "community_up09 = community_up09.set_index('building_id')\n",
    "community_up09['sample_weight'] = building_id_weight['sample_weight']*Total_dwelling_unit_count/building_id_weight['sample_weight'].sum()\n",
    "community_up09.to_csv(f'data_/community_building_samples/{community}/up09.csv')\n",
    "\n",
    "euss_up10 = pd.read_parquet('data_/euss_res_final_2018_550k_20220901/results_up10.parquet', engine='pyarrow')\n",
    "community_up10 = euss_up10.loc[euss_up00['building_id'].isin(building_id)]\n",
    "community_up10 = community_up10.set_index('building_id')\n",
    "community_up10['sample_weight'] = building_id_weight['sample_weight']*Total_dwelling_unit_count/building_id_weight['sample_weight'].sum()\n",
    "community_up10.to_csv(f'data_/community_building_samples/{community}/up10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0357c28a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
