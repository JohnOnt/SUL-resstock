{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Chicago: Transform ResStock PACKAGE Results to 15 SFD prototypes (Elevate Energy)\n",
    "Created on: 01/07/2020 \\\n",
    "By: Lixi Liu (Lixi.Liu@nrel.gov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "print(f'Notebook path: {os.getcwd()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download results online\n",
    "* unprocessed upgrade results: S3/resbldg-datasets/chicagoeui\n",
    "* processed result tables for plots: https://nrel.sharepoint.com/sites/ChicagoRetrofits/Shared%20Documents/Forms/AllItems.aspx?viewid=289cdd1a%2D97c9%2D4bcc%2D8416%2Dc19bf01c6302&id=%2Fsites%2FChicagoRetrofits%2FShared%20Documents%2FGeneral%2FUpgrade%20results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize\n",
    "For modifying plots, can go directly to section 2.3 after initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local path to downloaded results\n",
    "iteration = '03' # <----- options: 03\n",
    "iter_path = f'cookcnty_packages_{iteration}'\n",
    "result_dir = '/Users/lliu2/Documents/Chicago retrofits/ResStock results'\n",
    "result_path = os.path.join(result_dir, iter_path)\n",
    "\n",
    "## create folder for post-processed results:\n",
    "if not os.path.exists(os.path.join(result_path, 'processed results')):\n",
    "    os.mkdir(os.path.join(result_path, 'processed results'))\n",
    "    \n",
    "## create folder for exported baseline and upgrade results to csv (to share with Elevate):\n",
    "combined_res_csv_path = os.path.join(result_path, 'processed results', 'raw combined csvs')\n",
    "if not os.path.exists(combined_res_csv_path):\n",
    "    os.mkdir(combined_res_csv_path)\n",
    "    \n",
    "## create folder for plots:\n",
    "plot_path = os.path.join(result_path, 'processed results', 'plots')\n",
    "if not os.path.exists(plot_path):\n",
    "    os.mkdir(plot_path)\n",
    "\n",
    "print(f'Results path: \\n   {result_path}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_per_unit_sim_output(df, ref):\n",
    "    \"\"\"\n",
    "    ref (df): baseline df\n",
    "    \"\"\"\n",
    "    cols = [x for x in df.columns if \n",
    "            x.endswith('_kwh') or\n",
    "            x.endswith('_mbtu') or\n",
    "            x.endswith('_therm') or\n",
    "            x.endswith('_cost_usd') or\n",
    "            x.endswith('_ft_2')\n",
    "           ]\n",
    "    res = ref.set_index('building_id').reindex(df['building_id']).reset_index()\n",
    "    df.loc[:, cols] = df.loc[:, cols].replace([None,''],np.nan).divide(\n",
    "        res['build_existing_model.units_represented'], axis=0)\n",
    "    \n",
    "    return df\n",
    "print('func loaded: \"get_per_unit_sim_output\"')\n",
    "\n",
    "def get_per_unit_sim_output_limited(df, ref):\n",
    "    \"\"\"\n",
    "    To reduce computing time\n",
    "    ref (df): baseline df\n",
    "    \"\"\"\n",
    "    cols = ['simulation_output_report.total_site_natural_gas_therm',\n",
    "            'simulation_output_report.total_site_electricity_kwh',\n",
    "            'simulation_output_report.total_site_energy_mbtu',\n",
    "            'simulation_output_report.upgrade_cost_usd'\n",
    "           ]\n",
    "    res = ref.set_index('building_id').reindex(df['building_id']).reset_index()\n",
    "    df.loc[:, cols] = df.loc[:, cols].replace([None,''],np.nan).divide(\n",
    "        res['build_existing_model.units_represented'], axis=0)\n",
    "    \n",
    "    return df\n",
    "print('func loaded: \"get_per_unit_sim_output_limited\"')\n",
    "\n",
    "def add_sqft_eui(df, ref):\n",
    "    \"\"\"\n",
    "    ARG:\n",
    "        ref (df): baseline df\n",
    "    RETURN:\n",
    "        df with added cols: 'sqft', 'gas_eui_thermpersqft','elec_eui_kwhpersqft','site_eui_kbtupersqft'\n",
    "    \"\"\"\n",
    "    res = ref.set_index('building_id').reindex(df['building_id']).reset_index()\n",
    "    df['sqft'] = res['simulation_output_report.floor_area_conditioned_ft_2']\n",
    "    df['gas_eui_thermpersqft'] = df['simulation_output_report.total_site_natural_gas_therm'].divide(df['sqft']) # therm/sqft\n",
    "    df['elec_eui_kwhpersqft'] = df['simulation_output_report.total_site_electricity_kwh'].divide(df['sqft']) # kwh/sqft\n",
    "    df['site_eui_kbtupersqft'] = df['simulation_output_report.total_site_energy_mbtu'].divide(df['sqft'])*1000 # kbtu/sqft\n",
    "    \n",
    "    for col in ['sqft','gas_eui_thermpersqft','elec_eui_kwhpersqft','site_eui_kbtupersqft']:\n",
    "        df.loc[df['simulation_output_report.applicable']==False, col] = np.nan\n",
    "    \n",
    "    return df\n",
    "print('func loaded: \"add_sqft_eui\"')\n",
    "\n",
    "def get_res_by_prototype(df, filter_by_df, row):\n",
    "    \"\"\"\n",
    "    ARG:\n",
    "        df (dataframe): df to slice on\n",
    "        filter_by_df (dataframe): df used to do the slicing\n",
    "    RETURN:\n",
    "        filtered df (dataframe)\n",
    "    \"\"\"\n",
    "    slice_by_df = filter_by_df.copy().set_index('building_id').reindex(df['building_id']).reset_index()\n",
    "    res_group_i = df[slice_by_df['build_existing_model.geometry_stories'].isin(row['Stories'].split(',')) & \\\n",
    "        slice_by_df['build_existing_model.geometry_wall_type'].isin(row['WallType'].split(',')) & \\\n",
    "        slice_by_df['build_existing_model.vintage_acs'].isin(row['Vintage'].split(',')) & \\\n",
    "        slice_by_df['build_existing_model.geometry_building_type_recs'].isin(['Single-Family Detached'])]\n",
    "    res_group_i = res_group_i[res_group_i['completed_status']==\"Success\"]\n",
    "    \n",
    "    return res_group_i\n",
    "print('func loaded: \"get_res_by_prototype\"')\n",
    "\n",
    "def load_upgrade(n, file_dir=result_path):\n",
    "    \"\"\"\n",
    "    ARG:\n",
    "        n (int, str): upgrade number\n",
    "        file_dir (str): folder in which upgrade can be found, default to main result dir\n",
    "    RETURN:\n",
    "        df (dataframe) of upgrade n\n",
    "    \"\"\"\n",
    "    df = pd.read_parquet(os.path.join(file_dir,'upgrades',\n",
    "                                     f'upgrade={n}/results_up{n:02d}.parquet'))\n",
    "    return df\n",
    "print('func loaded: \"load_upgrade\"')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. BASELINE results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_a_copy_in_csv = True # <-----\n",
    "res = pd.read_parquet(os.path.join(result_path,'baseline','results_up00.parquet'))\n",
    "\n",
    "# (1) get sqft, gas/elec/site eui\n",
    "res = add_sqft_eui(res, res)\n",
    "res['build_existing_model.sample_weight'] = 2173432/40000\n",
    "\n",
    "if save_a_copy_in_csv:\n",
    "    res.to_csv(os.path.join(combined_res_csv_path,'results_baseline.csv'), index=False)\n",
    "    \n",
    "# (1) get sim output at the unit level (req for MF)\n",
    "res = get_per_unit_sim_output(res, res)\n",
    "\n",
    "# (2) get sqft, gas/elec/site eui - redo to get unit-level results\n",
    "res = add_sqft_eui(res, res)\n",
    "\n",
    "# check\n",
    "jobs_missing = set(range(1,100)) - set(res.job_id.unique())\n",
    "print(f'- {len(jobs_missing)} jobs missing: {jobs_missing}')\n",
    "print(f'- {16777-len(res)} buildings ({((16777-len(res))/16777*100):.2f}%)')\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign heating/cooling\n",
    "cooling_col = 'build_existing_model.hvac_cooling_type'\n",
    "heating_col = 'build_existing_model.hvac_heating_type_and_fuel'\n",
    "print('selected')\n",
    "\n",
    "# if using a national run\n",
    "if iteration == '_national_2018':\n",
    "    res = res[res['build_existing_model.ahs_region']=='CBSA Chicago-Naperville-Elgin, IL-IN-WI'].reset_index(drop=True)\n",
    "    res\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Check housing charateristics distributions in BASELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proto_chars = ['build_existing_model.geometry_stories',\n",
    "              'build_existing_model.geometry_wall_type',\n",
    "              'build_existing_model.vintage_acs',\n",
    "              cooling_col,\n",
    "              heating_col,\n",
    "              'build_existing_model.geometry_floor_area'\n",
    "             ]\n",
    "\n",
    "Ns = len(res.query('completed_status==\"Success\"')); N = len(res)\n",
    "print(f'>>> ResStock - {iter_path} - BASELINE result summary:\\n')\n",
    "print(f'  * {Ns} / {N} samples ran successfully, {N-Ns} failed, efficacy: {Ns/N:.1%} \\n')\n",
    "\n",
    "print('>>> Housing characteristics splits:\\n')\n",
    "\n",
    "Res_char = []\n",
    "for i, char in enumerate(proto_chars,1):\n",
    "    Nchar = res.groupby(char)['building_id'].count()\n",
    "    Nchar = Nchar/Ns\n",
    "    Nchar['N_failed'] = len(res[res[char].isnull()])\n",
    "    print(f'  * [{i}] {Nchar}\\n')\n",
    "    \n",
    "    ## append for export\n",
    "    Nchar = Nchar.rename('fraction').to_frame()\n",
    "    Nchar['housing_char'] = Nchar.index.name\n",
    "    Res_char.append(Nchar)\n",
    "    \n",
    "Res_char = pd.concat(Res_char, axis=0)\n",
    "Res_char.index.name = 'sub_char'\n",
    "Res_char = Res_char.reset_index()\n",
    "Res_char = Res_char[['housing_char','sub_char','fraction']]\n",
    "\n",
    "Res_char.to_csv(os.path.join(result_path, 'baseline', 'baseline_housing_char_breakdown.csv'), index=False)\n",
    "print(f'>>> file saved to:\\n  {os.path.join(result_path, \"baseline\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Add additional metrics to Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EE prototype tags\n",
    "res['vintage_ee'] = '3: post-1978'\n",
    "res.loc[res['build_existing_model.vintage_acs'].isin(['1940-59','1960-79']),'vintage_ee'] = '2: 1942-1978'\n",
    "res.loc[res['build_existing_model.vintage_acs']=='<1940','vintage_ee'] = '1: pre-1942'\n",
    "\n",
    "res['stories'] = '2: 2+ stories'\n",
    "res.loc[res['build_existing_model.geometry_stories']=='1','stories'] = '1: <2 stories'\n",
    "\n",
    "print('new cols added to \"res\"')\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Honnie's baseline bldgs of interest (IQR @ 50%)\n",
    "* Brick - Pre-1942 1-2+ Stories (here)\n",
    "* Frame - Pre-1942 1-2+ Stories (here)\n",
    "* Brick Mid Century (here)\n",
    "* Brick 2-4 Flat Pre-1942\n",
    "* Frame 2-4 Flat Pre-1942"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'site_eui_kbtupersqft'\n",
    "gb = ['build_existing_model.geometry_building_type_recs',\n",
    "      'build_existing_model.geometry_wall_type',\n",
    "      'vintage_ee']\n",
    "\n",
    "query = res.query('completed_status==\"Success\"').groupby(gb)[metric].describe()\n",
    "query.columns = [\".\".join([metric, x]) for x in query.columns]\n",
    "\n",
    "query.to_csv(\n",
    "    os.path.join(result_path, \"baseline_results_by_bldgtype_walltype_vintage_sfd.csv\")\n",
    ")\n",
    "\n",
    "query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Get BASELINE results by building prototypes from Elevate Energy\n",
    "#### Note: cannot add prototype tags directly to ResStock results as prototypes overlap in chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load prototype csv\n",
    "groups = pd.read_csv(os.path.join(result_dir,'Groups.csv'))\n",
    "print('prototypes loaded')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### (1) get count & median consumption\n",
    "Metric_map1 = {'count': 'completed_status',\n",
    "           'median gas': 'simulation_output_report.total_site_natural_gas_therm',\n",
    "           'median elec': 'simulation_output_report.total_site_electricity_kwh'}\n",
    "\n",
    "for i, row in groups.iterrows():\n",
    "    res_group_i = get_res_by_prototype(res, res, row) # <----\n",
    "    \n",
    "    for metric, res_var in Metric_map1.items():\n",
    "        if metric == 'count':\n",
    "            groups.loc[i, 'count'] = len(res_group_i)\n",
    "        else:\n",
    "            groups.loc[i, metric] = res_group_i[res_var].median()\n",
    "\n",
    "groups['Gas Diff-med(%)'] = ((groups['Non-normalized gas usage'] - groups['median gas']) / groups['Non-normalized gas usage']) * 100\n",
    "groups['Elec Diff-med(%)'] = ((groups['Non-normalized elec. usage'] - groups['median elec']) / groups['Non-normalized elec. usage']) * 100\n",
    "print('>> (1) median consumption computed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = []\n",
    "\n",
    "for i, row in groups.iterrows():\n",
    "    if row['HousingGroupName'] not in \\\n",
    "        ['Masonry All Years Split Level','Frame Post-1978 Split Level','Frame Pre-1942 Split Level']:\n",
    "        res_group_i = get_res_by_prototype(res, res, row) # <----\n",
    "        res_group_i['prototype'] = row['HousingGroupName']\n",
    "        res2.append(res_group_i)\n",
    "\n",
    "res2 = pd.concat(res2, axis=0).sort_values(by=['building_id'])\n",
    "display(res2)\n",
    "\n",
    "res2 = res2.set_index('building_id').reindex(res['building_id']).reset_index()\n",
    "res.loc[res2['prototype'].isnull(),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### (2) get mean consumption\n",
    "Metric_map2 = {'mean gas': 'simulation_output_report.total_site_natural_gas_therm',\n",
    "           'mean elec': 'simulation_output_report.total_site_electricity_kwh'} # metric: res_var\n",
    "\n",
    "for i, row in groups.iterrows():\n",
    "    res_group_i = get_res_by_prototype(res, res, row) # <----\n",
    "    \n",
    "    for metric, res_var in Metric_map2.items():\n",
    "        groups.loc[i, metric] = res_group_i[res_var].mean()\n",
    "\n",
    "groups['Gas Diff-mean(%)'] = ((groups['Non-normalized gas usage'] - groups['mean gas']) / groups['Non-normalized gas usage']) * 100\n",
    "groups['Elec Diff-mean(%)'] = ((groups['Non-normalized elec. usage'] - groups['mean elec']) / groups['Non-normalized elec. usage']) * 100\n",
    "print('>> (2) mean consumption computed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### (3) get median & mean sqft & eui\n",
    "Metric_map1 = {'median sqft': 'sqft',\n",
    "               'median gas eui': 'gas_eui_thermpersqft', \n",
    "               'median elec eui': 'elec_eui_kwhpersqft'}\n",
    "Metric_map2 = {'mean sqft': 'sqft', \n",
    "               'mean gas eui': 'gas_eui_thermpersqft', \n",
    "               'mean elec eui': 'elec_eui_kwhpersqft'}\n",
    "\n",
    "for i, row in groups.iterrows():\n",
    "    res_group_i = get_res_by_prototype(res, res, row) # <----\n",
    "    \n",
    "    ### (3.1) get median values\n",
    "    for metric, res_var in Metric_map1.items():\n",
    "        groups.loc[i, metric] = res_group_i[res_var].median()\n",
    "\n",
    "    ### (3.2) get mean values\n",
    "    for metric, res_var in Metric_map2.items():\n",
    "        groups.loc[i, metric] = \\\n",
    "            res_group_i[res_var].mean()\n",
    "\n",
    "print('>> (3) median & mean sqft & eui computed:');\n",
    "\n",
    "groups.set_index(['HousingGroupNo','HousingGroupName'])[['median sqft', 'mean sqft',\n",
    "                                                         'median gas','mean gas',\n",
    "                                                         'median gas eui', 'mean gas eui', \n",
    "                                                         'median elec','mean elec', \n",
    "                                                         'median elec eui','mean elec eui']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### export BASELINE prototype summary\n",
    "groups.to_csv(os.path.join(result_path, 'baseline', 'baseline_prototype_results.csv'), index=True)\n",
    "print(f'BASELINE prototype summary saved to:\\n  {os.path.join(result_path, \"baseline\")}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2A. PACKAGE post processing ###\n",
    "Three packages were ran as partitioned files. See \"Cookcnty_packages_02.yml\" for info\n",
    "#### (1) Packages WITHOUT partitions (N=1, pkg 06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_and_correct_for_missing_buildings(Pi, res, upgrade_no):\n",
    "    delta = len(res)-len(Pi)\n",
    "    if delta>0:\n",
    "        print(f'   - upgrade_{upgrade_no:02d} is missing {delta} buildings compared to baseline')\n",
    "    # always reindex\n",
    "    Pi = Pi.set_index('building_id').reindex(res['building_id']).reset_index()\n",
    "        \n",
    "    return Pi\n",
    "\n",
    "'func \"check_and_correct_for_missing_buildings\" loaded'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Packages WITH single-level partitions (N=10, pkg 07-16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 partitiions over 'Attic Insulation'\n",
    "\n",
    "def combine_df_from_first_level_partitions(pkg_no, upgrade_list, partition_para, options_list_for_first_upgrades, \n",
    "                                           MSHP_option=None, nullify_total_ng=False, save_as_csv=True, \n",
    "                                           recreate_from_scratch=True):\n",
    "    global res\n",
    "    \"\"\"\n",
    "    ARGS:\n",
    "        pkg_no (int): package number to assign to combined df\n",
    "        upgrade_list (list): list of ResStock upgrades to combine\n",
    "        partition_para (str): para to filter the upgrades by and combine\n",
    "        options_list_for_first_upgrades (list of list): list of para options to filter the first n-1 upgrades by\n",
    "        MSHP_option (int): option number in package to correct, default to None\n",
    "        nullify_total_ng (bool): default to False, set total NG use to 0, for electrification package only\n",
    "        save_as_csv (bool): default to True\n",
    "        recreate_from_scratch (bool): default to True\n",
    "    \n",
    "    RETURN:\n",
    "        P1: combined df\n",
    "    \"\"\"\n",
    "    file = f'package{pkg_no:02d}.csv'\n",
    "    filename = os.path.join(combined_res_csv_path, file)\n",
    "    print(f'* {file}, from upgrades: {upgrade_list}')\n",
    "    \n",
    "    N = len(upgrade_list)\n",
    "    partition_para = f'build_existing_model.{partition_para}'\n",
    "    \n",
    "    # check setting:\n",
    "    if N-1 != len(options_list_for_first_upgrades):\n",
    "        raise ValueError(f'The size of \"options_list_for_first_upgrades\" = {len(options_list_for_first_upgrades)}, '+\n",
    "                         f'is not 1 less than the size of \"upgrade_list\" = {N}')\n",
    "\n",
    "    if not os.path.exists(filename) or recreate_from_scratch:\n",
    "        print(f'building from resstock results... partitioned by:\\n  \"{partition_para}\"')\n",
    "\n",
    "        ## (1) building ids for each partitions based on partition_para and para_options\n",
    "        bldg_list = options_list = []; msg = ' '; n_bldgs = 0\n",
    "        for n in range(N-1):\n",
    "            bldgs_for_part_n = res[res[partition_para].isin(options_list_for_first_upgrades[n])]['building_id']\n",
    "            bldg_list.append(bldgs_for_part_n)\n",
    "            \n",
    "            options_for_part_n = options_list_for_first_upgrades[n]\n",
    "            options_list = options_list + options_for_part_n\n",
    "            \n",
    "            n_bldgs += len(bldgs_for_part_n)\n",
    "            msg += f' part {n+1}: {len(bldgs_for_part_n)},'\n",
    "        \n",
    "        # for last partition:\n",
    "        bldgs_for_part_n = res[~res[partition_para].isin(options_list)]['building_id']\n",
    "        bldg_list.append(bldgs_for_part_n)\n",
    "        \n",
    "        n_bldgs += len(bldgs_for_part_n)\n",
    "        msg += f' part {N}: {len(bldgs_for_part_n)}, total: {n_bldgs}'\n",
    "        print(msg)\n",
    "\n",
    "        ## (2) combine partitions and update upgrade name\n",
    "        P1 = []\n",
    "        for up, Bi in zip(upgrade_list, bldg_list):\n",
    "            p = load_upgrade(up, result_path)\n",
    "            p = check_and_correct_for_missing_buildings(p, res, up)\n",
    "            P1.append(p[p['building_id'].isin(Bi)])\n",
    "\n",
    "        P1 = pd.concat(P1, axis=0).sort_index()\n",
    "\n",
    "        P1['apply_upgrade.upgrade_part'] = P1['apply_upgrade.upgrade_name'] # new col to show partition #\n",
    "        P1['apply_upgrade.upgrade_name'] = P1['apply_upgrade.upgrade_name'].apply(\n",
    "            lambda x: ' '.join(str(x).split(' ')[:-3])) # update name\n",
    "        \n",
    "        ## (3) correct MSHP costs\n",
    "        if not MSHP_option == None:\n",
    "            print('\\nrecalculating MSHP cost...')\n",
    "            MSHP_cost = f'simulation_output_report.option_{MSHP_option:02d}_cost_usd'\n",
    "            \n",
    "            # rename orig upgrade_cost col\n",
    "            if not 'simulation_output_report.upgrade_cost_usd_orig' in P1.columns:\n",
    "                P1['simulation_output_report.upgrade_cost_usd_orig'] = P1['simulation_output_report.upgrade_cost_usd']\n",
    "\n",
    "            # copy upgrade_cost col\n",
    "            P1['simulation_output_report.upgrade_cost_usd'] = P1['simulation_output_report.upgrade_cost_usd_orig']\n",
    "\n",
    "            # remove old MSHP cost\n",
    "            P1['simulation_output_report.upgrade_cost_usd'] -= P1[MSHP_cost]\n",
    "\n",
    "            # recalc upgrade costs for MSHP\n",
    "            idx = (P1['simulation_output_report.applicable']==True) & (res['build_existing_model.hvac_has_ducts']=='No')\n",
    "            P1.loc[idx, MSHP_cost] = \\\n",
    "                710 + (95+1800/12)*P1.loc[idx, 'simulation_output_report.size_heating_system_kbtu_h']\n",
    "\n",
    "            # calculate backup heating system size and cost\n",
    "            supp_heat_cost = 38 # <--- 38(avg) 28-47 [$/kBtu_h]\n",
    "            P1['simulation_output_report.size_heating_supp_system_kbtu_h_mshp'] = np.nan\n",
    "            P1.loc[idx, 'simulation_output_report.size_heating_supp_system_kbtu_h_mshp'] = \\\n",
    "                P1.loc[idx, 'simulation_output_report.hvac_heating_supp_capacity_w']*3.412142/1000\n",
    "\n",
    "            P1['simulation_output_report.upgrade_cost_usd_supp_heat_mshp'] = np.nan\n",
    "            P1.loc[idx, 'simulation_output_report.upgrade_cost_usd_supp_heat_mshp'] = \\\n",
    "                supp_heat_cost * P1.loc[idx, 'simulation_output_report.size_heating_supp_system_kbtu_h_mshp']\n",
    "\n",
    "            # add new MSHP and backup heat cost to 'upgrade_cost_usd'\n",
    "            P1.loc[idx, 'simulation_output_report.upgrade_cost_usd'] += \\\n",
    "                P1.loc[idx, MSHP_cost]\n",
    "\n",
    "            P1.loc[idx, 'simulation_output_report.upgrade_cost_usd'] += \\\n",
    "                P1.loc[idx, 'simulation_output_report.upgrade_cost_usd_supp_heat_mshp']\n",
    "\n",
    "            # show\n",
    "            print(f'>> package={pkg_no:02d} modified cols:')\n",
    "            display(P1.loc[idx, ['apply_upgrade.upgrade_name',\n",
    "                                'simulation_output_report.upgrade_cost_usd_orig',\n",
    "                                'simulation_output_report.upgrade_cost_usd', # updated\n",
    "                                'simulation_output_report.upgrade_cost_usd_supp_heat_mshp', # new\n",
    "                                'simulation_output_report.size_heating_supp_system_kbtu_h_mshp', # new\n",
    "                               ]])\n",
    "            \n",
    "        ## (4) manually set total NG therm to 0 if pkg is electrification\n",
    "        if nullify_total_ng:\n",
    "            P1.loc[P1['simulation_output_report.applicable']==True,\n",
    "                   'simulation_output_report.total_site_natural_gas_therm'] = 0\n",
    "\n",
    "        ## (5) save\n",
    "        if save_as_csv:\n",
    "            print(f'\\n>> combined file saved to: {combined_res_csv_path}')\n",
    "            P1.to_csv(filename, index=False)\n",
    "            \n",
    "    else:\n",
    "        P1 = pd.read_csv(filename)\n",
    "\n",
    "#     display(P1)\n",
    "    return P1\n",
    "\n",
    "print('func \"combine_df_from_two_partitions\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkg_no = 11\n",
    "upgrade_list = [1, 2]\n",
    "partition_para = 'infiltration'\n",
    "options_list_for_first_upgrades = [\n",
    "    ['50 ACH50','40 ACH50','30 ACH50','25 ACH50','20 ACH50','15 ACH50','10 ACH50','8 ACH50'],\n",
    "]\n",
    "MSHP_option = None\n",
    "\n",
    "combine_df_from_first_level_partitions(pkg_no, upgrade_list, partition_para, options_list_for_first_upgrades, \n",
    "                                       MSHP_option, nullify_total_ng=False, save_as_csv=True, \n",
    "                                       recreate_from_scratch=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkg_no = 13\n",
    "upgrade_list = [3, 4]\n",
    "partition_para = 'infiltration'\n",
    "options_list_for_first_upgrades = [\n",
    "    ['50 ACH50','40 ACH50','30 ACH50','25 ACH50','20 ACH50','15 ACH50','10 ACH50','8 ACH50'],\n",
    "]\n",
    "MSHP_option = None\n",
    "\n",
    "combine_df_from_first_level_partitions(pkg_no, upgrade_list, partition_para, options_list_for_first_upgrades, \n",
    "                                       MSHP_option, nullify_total_ng=False, save_as_csv=True, \n",
    "                                       recreate_from_scratch=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) Packages WITH multi-level partitions (N=4, pkg 17-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_df_from_two_level_partitions(pkg_no, upgrade_list, level1_list, level2_list, MSHP_option=None, \n",
    "                                         fix_upgrade_name=False, nullify_total_ng=False, save_as_csv=True, \n",
    "                                         recreate_from_scratch=True):\n",
    "    global res\n",
    "    \"\"\"\n",
    "    ARGS:\n",
    "        pkg_no (int): package number to assign to combined df\n",
    "        upgrade_list (list): list of ResStock upgrades to combine\n",
    "        level1_list (list of dict): list of dictionaries defining the level 1 partition key and options\n",
    "        level2_list (list of dict): list of dictionaries defining the level 2 partition key and options\n",
    "        MSHP_option (int): option number in package to correct, default to None\n",
    "        fix_upgrade_name (bool): default to True, for pkg 21-24 only\n",
    "        nullify_total_ng (bool): default to False, set total NG use to 0, for electrification package only\n",
    "        save_as_csv (bool): default to True\n",
    "        recreate_from_scratch (bool): default to True\n",
    "    \n",
    "    RETURN:\n",
    "        P1: combined df\n",
    "    \"\"\"\n",
    "    \n",
    "    file = f'package{pkg_no:02d}.csv'\n",
    "    filename = os.path.join(combined_res_csv_path, file)\n",
    "    print(f'* {file}, from upgrades: {upgrade_list}')\n",
    "    \n",
    "    N_upgrades = len(upgrade_list)\n",
    "    N_partitions = len(level1_list)*len(level2_list)\n",
    "    if N_upgrades != N_partitions:\n",
    "        raise ValueError(f'The size of \"upgrade_list\" = {N_upgrades} does not match the number of enumeration from '+\n",
    "                        f'\"level1_list\" and \"level2_list\" = {N_partitions}')\n",
    "    \n",
    "    if not os.path.exists(filename) or recreate_from_scratch:\n",
    "        \n",
    "        print(f'building from resstock run results, {N_partitions} partitions...\\n')\n",
    "\n",
    "        ## building ids for each partitions\n",
    "        bldg_list = []; CBi_len = 0\n",
    "\n",
    "        ##### level 1\n",
    "        P4C1 = level1_list # <----\n",
    "        for i , Ci in enumerate(P4C1,1):\n",
    "            CBi = set()\n",
    "            for key, lst in Ci.items():\n",
    "                Bi = res[res[f'build_existing_model.{key}'].replace({np.nan:'None'}).isin(lst)]['building_id']\n",
    "                CBi = CBi.union(set(list(Bi)))\n",
    "                print(f'- 1.{i} {key}, {len(Bi)} / {len(res)}')\n",
    "            print(f'- 1.{i} total, {len(CBi)}')\n",
    "            res1 = res[res[f'building_id'].isin(CBi)]\n",
    "\n",
    "            ##### level 2\n",
    "            P4C2 = level2_list # <----\n",
    "            CBi_2all = set(); CBi_2len = 0\n",
    "            for k, Ci in enumerate(P4C2,1):\n",
    "                if k == len(P4C2):\n",
    "                    CBi = set(list(res1['building_id'])).difference(CBi_2all)\n",
    "                    print(f'    + 3.{k} total, {len(CBi)}')\n",
    "                else:\n",
    "                    CBi = set()\n",
    "                    for key, lst in Ci.items():\n",
    "                        Bi = res1[res1[f'build_existing_model.{key}'].isin(lst)]['building_id']\n",
    "                        CBi = CBi.union(set(list(Bi)))\n",
    "                        print(f'    + 3.{k} {key}, {len(Bi)} / {len(res1)}')\n",
    "                CBi_2all = CBi_2all.union(CBi)\n",
    "                bldg_list.append(CBi)\n",
    "\n",
    "                CBi_2len += len(CBi)\n",
    "                CBi_len += len(CBi)\n",
    "                print(f'appending total {len(CBi)}, (1.{i})(2.{k})_culm = {CBi_2len}, overall_culm = {CBi_len}\\n')\n",
    "\n",
    "        ## (2) combine partitions, update upgrade name\n",
    "        P4 = []\n",
    "        for up, Bi in zip(upgrade_list, bldg_list):\n",
    "            p = load_upgrade(up, result_path)\n",
    "            p = check_and_correct_for_missing_buildings(p, res, up)\n",
    "            P4.append(p[p['building_id'].isin(Bi)])\n",
    "\n",
    "        P4 = pd.concat(P4, axis=0).sort_index()\n",
    "\n",
    "        P4['apply_upgrade.upgrade_part'] = P4['apply_upgrade.upgrade_name'] # new col to show partition #\n",
    "        P4['apply_upgrade.upgrade_name'] = P4['apply_upgrade.upgrade_name'].apply(\n",
    "            lambda x: ' '.join(str(x).split(' ')[:-3])) # update name\n",
    "        \n",
    "        ## (3) correct MSHP costs\n",
    "        if not MSHP_option == None:\n",
    "            print('\\nrecalculating MSHP cost...')\n",
    "            MSHP_cost = f'simulation_output_report.option_{MSHP_option:02d}_cost_usd'\n",
    "            \n",
    "            # rename orig upgrade_cost col\n",
    "            if not 'simulation_output_report.upgrade_cost_usd_orig' in P4.columns:\n",
    "                P4['simulation_output_report.upgrade_cost_usd_orig'] = P4['simulation_output_report.upgrade_cost_usd']\n",
    "\n",
    "            # copy upgrade_cost col\n",
    "            P4['simulation_output_report.upgrade_cost_usd'] = P4['simulation_output_report.upgrade_cost_usd_orig']\n",
    "\n",
    "            # remove old MSHP cost\n",
    "            P4['simulation_output_report.upgrade_cost_usd'] -= P4[MSHP_cost]\n",
    "\n",
    "            # recalc upgrade costs for MSHP\n",
    "            idx = (P4['simulation_output_report.applicable']==True) & (res['build_existing_model.hvac_has_ducts']=='No')\n",
    "            P4.loc[idx, MSHP_cost] = \\\n",
    "                710 + (95+1800/12)*P4.loc[idx, 'simulation_output_report.size_heating_system_kbtu_h']\n",
    "\n",
    "            # calculate backup heating system size and cost\n",
    "            supp_heat_cost = 38 # <--- 38(avg) 28-47 [$/kBtu_h]\n",
    "            P4['simulation_output_report.size_heating_supp_system_kbtu_h_mshp'] = np.nan\n",
    "            P4.loc[idx, 'simulation_output_report.size_heating_supp_system_kbtu_h_mshp'] = \\\n",
    "                P4.loc[idx, 'simulation_output_report.hvac_heating_supp_capacity_w']*3.412142/1000\n",
    "\n",
    "            P4['simulation_output_report.upgrade_cost_usd_supp_heat_mshp'] = np.nan\n",
    "            P4.loc[idx, 'simulation_output_report.upgrade_cost_usd_supp_heat_mshp'] = \\\n",
    "                supp_heat_cost * P4.loc[idx, 'simulation_output_report.size_heating_supp_system_kbtu_h_mshp']\n",
    "\n",
    "            # add new MSHP and backup heat cost to 'upgrade_cost_usd'\n",
    "            P4.loc[idx, 'simulation_output_report.upgrade_cost_usd'] += \\\n",
    "                P4.loc[idx, MSHP_cost]\n",
    "\n",
    "            P4.loc[idx, 'simulation_output_report.upgrade_cost_usd'] += \\\n",
    "                P4.loc[idx, 'simulation_output_report.upgrade_cost_usd_supp_heat_mshp']\n",
    "\n",
    "            # show\n",
    "            print(f'>> package={pkg_no:02d} modified cols:')\n",
    "            display(P4.loc[idx, ['apply_upgrade.upgrade_name',\n",
    "                                'simulation_output_report.upgrade_cost_usd_orig',\n",
    "                                'simulation_output_report.upgrade_cost_usd', # updated\n",
    "                                'simulation_output_report.upgrade_cost_usd_supp_heat_mshp', # new\n",
    "                                'simulation_output_report.size_heating_supp_system_kbtu_h_mshp', # new\n",
    "                               ]])\n",
    "            \n",
    "        ## (4) fix upgrade name\n",
    "        try:\n",
    "            P4[['apply_upgrade.upgrade_name','apply_upgrade.upgrade_part']] = \\\n",
    "                P4[['apply_upgrade.upgrade_name','apply_upgrade.upgrade_part']].apply(\n",
    "                lambda x: x.str.replace('low-E Window','Low-Gain Window')) # fix upgrade name\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        ## (5) manually set total NG therm to 0 if pkg is electrification\n",
    "        if nullify_total_ng:\n",
    "            P4.loc[P4['simulation_output_report.applicable']==True,\n",
    "                   'simulation_output_report.total_site_natural_gas_therm'] = 0\n",
    "\n",
    "        ## (6) save\n",
    "        P4.to_csv(filename, index=False)\n",
    "\n",
    "    else:              \n",
    "        P4 = pd.read_csv(filename)\n",
    "    \n",
    "    return P4\n",
    "\n",
    "print('func \"combine_df_from_two_level_partitions\" loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkg_no = 17 # <----\n",
    "upgrade_list = list(range(5, 5+8)) # <----\n",
    "MSHP_option = None \n",
    "fix_upgrade_name = False\n",
    "    \n",
    "## (1) get partition keys and options\n",
    "# para 1 -- 4 parts #######\n",
    "key = 'infiltration'\n",
    "PC = [\n",
    "    {key: ['50 ACH50','40 ACH50','30 ACH50','25 ACH50']},\n",
    "    {key: ['20 ACH50','15 ACH50','10 ACH50','8 ACH50']},\n",
    "    {key: ['7 ACH50','6 ACH50','5 ACH50']},\n",
    "]\n",
    "\n",
    "options = []\n",
    "for Ci in PC:\n",
    "    options = options + list(Ci.values())\n",
    "options = [item for sublist in options for item in sublist] \n",
    "options = list(set(res[f'build_existing_model.{key}'].replace(np.nan, 'None').unique()) - set(options))\n",
    "PC.append({key: options})\n",
    "level1_list = PC.copy() # <----\n",
    "\n",
    "# para 2 -- 2 parts #######\n",
    "key = 'insulation_unfinished_attic'\n",
    "PC = [\n",
    "    {key: ['Uninsulated, Vented', 'Ceiling R-7, Vented', 'Ceiling R-13, Vented']},\n",
    "]\n",
    "\n",
    "options = []\n",
    "for Ci in PC:\n",
    "    options = options + list(Ci.values())\n",
    "options = [item for sublist in options for item in sublist] \n",
    "options = list(set(res[f'build_existing_model.{key}'].replace(np.nan, 'None').unique()) - set(options))\n",
    "PC.append({key: options})\n",
    "level2_list = PC.copy() # <----\n",
    "    \n",
    "# (2) create df\n",
    "combine_df_from_two_level_partitions(pkg_no, upgrade_list, level1_list, level2_list, MSHP_option,\n",
    "                                     fix_upgrade_name, nullify_total_ng=True, save_as_csv=True, \n",
    "                                     recreate_from_scratch=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkg_no = 18 # <----\n",
    "upgrade_list = list(range(13, 13+12)) # <----\n",
    "MSHP_option = None #5 # <----\n",
    "fix_upgrade_name = False\n",
    "\n",
    "## (1) get partition keys and options\n",
    "# para 1 -- 4 parts  #######\n",
    "key = 'infiltration'\n",
    "PC = [\n",
    "    {key: ['50 ACH50','40 ACH50','30 ACH50','25 ACH50']},\n",
    "    {key: ['20 ACH50','15 ACH50','10 ACH50','8 ACH50']},\n",
    "    {key: ['7 ACH50','6 ACH50','5 ACH50']},\n",
    "]\n",
    "\n",
    "options = []\n",
    "for Ci in PC:\n",
    "    options = options + list(Ci.values())\n",
    "options = [item for sublist in options for item in sublist] \n",
    "options = list(set(res[f'build_existing_model.{key}'].replace(np.nan, 'None').unique()) - set(options))\n",
    "PC.append({key: options})\n",
    "level1_list = PC.copy() # <----\n",
    "\n",
    "# para 2 -- 3 parts #######\n",
    "key = 'insulation_unfinished_attic'\n",
    "PC = [\n",
    "    {key: ['Uninsulated, Vented', 'Ceiling R-7, Vented']},\n",
    "    {key: ['Ceiling R-13, Vented', 'Ceiling R-19, Vented']},\n",
    "]\n",
    "\n",
    "options = []\n",
    "for Ci in PC:\n",
    "    options = options + list(Ci.values())\n",
    "options = [item for sublist in options for item in sublist] \n",
    "options = list(set(res[f'build_existing_model.{key}'].replace(np.nan, 'None').unique()) - set(options))\n",
    "PC.append({key: options})\n",
    "level2_list = PC.copy() # <----\n",
    "    \n",
    "# (2) create df\n",
    "combine_df_from_two_level_partitions(pkg_no, upgrade_list, level1_list, level2_list, MSHP_option,\n",
    "                                     fix_upgrade_name, nullify_total_ng=True, save_as_csv=True, \n",
    "                                     recreate_from_scratch=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2B. PACKAGE summary ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### upgrade result processing funcs\n",
    "def assign_utility_rates_to_upgrade(upkg_no, p, ref, HVAC_upgrades_rate_change, for_packages=False):\n",
    "    \n",
    "    res = ref.set_index('building_id')[['gas_rate', 'gas_fixed', 'gas_CO2_rate',\n",
    "                                        'elec_rate', 'elec_fixed', 'elec_CO2_rate'\n",
    "                                       ]]\n",
    "    ## assign rates\n",
    "    p['gas_rate'] = p['building_id'].map(res['gas_rate'])\n",
    "    p['gas_fixed'] = p['building_id'].map(res['gas_fixed'])\n",
    "    p['gas_CO2_rate'] = p['building_id'].map(res['gas_CO2_rate'])\n",
    "    p['elec_rate'] = p['building_id'].map(res['elec_rate'])\n",
    "    p['elec_fixed'] = p['building_id'].map(res['elec_fixed'])\n",
    "    p['elec_CO2_rate'] = p['building_id'].map(res['elec_CO2_rate'])\n",
    "    \n",
    "    if not for_packages:\n",
    "        # ind upgrades\n",
    "        for n in HVAC_upgrades_rate_change.keys():\n",
    "            new_rates = HVAC_upgrades_rate_change[n]\n",
    "            p.loc[p['simulation_output_report.applicable']==True, 'gas_rate'] = new_rates[0]\n",
    "            p.loc[p['simulation_output_report.applicable']==True, 'gas_fixed'] = new_rates[1]\n",
    "            p.loc[p['simulation_output_report.applicable']==True, 'elec_rate'] = new_rates[2]\n",
    "            p.loc[p['simulation_output_report.applicable']==True, 'elec_fixed'] = new_rates[3]\n",
    "    else:\n",
    "        if isinstance(HVAC_upgrades_rate_change, dict):\n",
    "            # packages with a dict input\n",
    "            if upkg_no in HVAC_upgrades_rate_change.keys():\n",
    "                for m in HVAC_upgrades_rate_change[upkg_no]:\n",
    "                    idx = (p[(p['apply_upgrade.applicable']==True) &\n",
    "                           (~p[f'simulation_output_report.option_{m:02d}_cost_usd'].isnull())\n",
    "                            ]).index\n",
    "                    p.loc[idx, 'gas_rate'] = NGH_rate\n",
    "                    p.loc[idx, 'gas_fixed'] = NGH_fixed\n",
    "                    p.loc[idx, 'elec_rate'] = EH_rate\n",
    "                    p.loc[idx, 'elec_fixed'] = EH_fixed\n",
    "        \n",
    "        else:\n",
    "            # packages with a list input\n",
    "            for m in HVAC_upgrades_rate_change:\n",
    "                idx = (p[(p['apply_upgrade.applicable']==True) &\n",
    "                       (~p[f'simulation_output_report.option_{m:02d}_cost_usd'].isnull())\n",
    "                        ]).index\n",
    "                p.loc[idx, 'gas_rate'] = NGH_rate\n",
    "                p.loc[idx, 'gas_fixed'] = NGH_fixed\n",
    "                p.loc[idx, 'elec_rate'] = EH_rate\n",
    "                p.loc[idx, 'elec_fixed'] = EH_fixed\n",
    "                \n",
    "    # assign 0 rates to building with no energy use  \n",
    "    p.loc[p['simulation_output_report.total_site_natural_gas_therm'].isin([0, np.nan]), 'gas_fixed'] = 0 \n",
    "    p.loc[p['simulation_output_report.total_site_natural_gas_therm'].isin([0, np.nan]), 'gas_rate'] = 0 \n",
    "    p.loc[p['simulation_output_report.total_site_electricity_kwh'].isin([0, np.nan]), 'elec_fixed'] = 0 \n",
    "    p.loc[p['simulation_output_report.total_site_electricity_kwh'].isin([0, np.nan]), 'elec_rate'] = 0 \n",
    "    \n",
    "    for col in ['gas_rate','gas_fixed','gas_CO2_rate','elec_rate','elec_fixed','elec_CO2_rate']:\n",
    "        p.loc[p['simulation_output_report.applicable']==False, col] = np.nan\n",
    "\n",
    "    return p\n",
    "\n",
    "def combine_upgrade_cost_and_lifetime(p):\n",
    "    \n",
    "    ## upgrade costs (sum)\n",
    "    p['upgrade_cost'] = p['simulation_output_report.upgrade_cost_usd']\n",
    "    cost_cols = list(x for x in p.columns if x.endswith('cost_usd'))\n",
    "    p = p.drop(cost_cols, axis=1)\n",
    "    \n",
    "    ## upgrade lifetime (min)\n",
    "    lt_cols = list(x for x in p.columns if x.endswith('lifetime_yrs'))\n",
    "    p['upgrade_lifetime'] = p[lt_cols].min(axis=1)\n",
    "    p = p.drop(lt_cols, axis=1)\n",
    "\n",
    "    p['upgrade_cost'] = p['upgrade_cost'].replace([0, None,''],np.nan)\n",
    "    p['upgrade_lifetime'] = p['upgrade_lifetime'].replace([0, None,''],np.nan)\n",
    "    \n",
    "    return p\n",
    "\n",
    "def get_annual_totals(pp, get_col_only=False):\n",
    "    if get_col_only:\n",
    "        p = pp.copy()\n",
    "    else:\n",
    "        p = pp\n",
    "        \n",
    "    p['ann_gas_cost'] = \\\n",
    "        p['simulation_output_report.total_site_natural_gas_therm']*p['gas_rate']+p['gas_fixed']\n",
    "    p['ann_elec_cost'] = \\\n",
    "        p['simulation_output_report.total_site_electricity_kwh']*p['elec_rate']+p['elec_fixed']\n",
    "    p['ann_energy_cost'] = \\\n",
    "        p['ann_gas_cost'] + p['ann_elec_cost']\n",
    "    \n",
    "    p['ann_metric_ton_co2e_gas'] = \\\n",
    "        p['simulation_output_report.total_site_natural_gas_therm']*p['gas_CO2_rate']\n",
    "    p['ann_metric_ton_co2e_elec'] = \\\n",
    "        p['simulation_output_report.total_site_electricity_kwh']*p['elec_CO2_rate']\n",
    "    p['ann_metric_ton_co2e'] = \\\n",
    "        p['ann_metric_ton_co2e_gas'] + p['ann_metric_ton_co2e_elec']\n",
    "    \n",
    "    if get_col_only:\n",
    "        return p[['ann_gas_cost','ann_elec_cost','ann_energy_cost',\n",
    "                 'ann_metric_ton_co2e_gas','ann_metric_ton_co2e_elec','ann_metric_ton_co2e']]\n",
    "    else:\n",
    "        return p\n",
    "\n",
    "def get_annual_gas_elec_site_energy_saving(pp, res, get_col_only=False):\n",
    "    \"\"\"\n",
    "    p: upgrade df\n",
    "    ref: reference scenario df\n",
    "    get_col_only: whether to return the computed col only or the entire upgrade df p\n",
    "    \"\"\"\n",
    "    if get_col_only:\n",
    "        p = pp.copy()\n",
    "    else:\n",
    "        p = pp\n",
    "    ref = res.set_index('building_id').reindex(p['building_id']).reset_index()\n",
    "    \n",
    "    p['ann_therm_gas_saving'] = ref['simulation_output_report.total_site_natural_gas_therm']-\\\n",
    "         p['simulation_output_report.total_site_natural_gas_therm']\n",
    "    p['ann_kwh_elec_saving'] = ref['simulation_output_report.total_site_electricity_kwh']-\\\n",
    "         p['simulation_output_report.total_site_electricity_kwh']\n",
    "    p['ann_mbtu_site_energy_saving'] = ref['simulation_output_report.total_site_energy_mbtu']-\\\n",
    "        p['simulation_output_report.total_site_energy_mbtu']\n",
    "    \n",
    "    if get_col_only:\n",
    "        return p[['ann_therm_gas_saving','ann_kwh_elec_saving','ann_mbtu_site_energy_saving']]\n",
    "    else:\n",
    "        return p\n",
    "\n",
    "def get_annual_energy_cost_saving(pp, res, get_col_only=False):\n",
    "    \"\"\"\n",
    "    p: upgrade df\n",
    "    ref: reference scenario df\n",
    "    get_col_only: whether to return the computed col only or the entire upgrade df p\n",
    "    \"\"\" \n",
    "    if get_col_only:\n",
    "        p = pp.copy()\n",
    "    else:\n",
    "        p = pp\n",
    "    ref = res.set_index('building_id').reindex(p['building_id']).reset_index()\n",
    "    \n",
    "    p['ann_gas_cost_saving'] = \\\n",
    "        ref['simulation_output_report.total_site_natural_gas_therm']*ref['gas_rate']+ref['gas_fixed'] - \\\n",
    "        (p['simulation_output_report.total_site_natural_gas_therm']*p['gas_rate']+p['gas_fixed'])\n",
    "        \n",
    "    p['ann_elec_cost_saving'] = \\\n",
    "        ref['simulation_output_report.total_site_electricity_kwh']*ref['elec_rate']+ref['elec_fixed'] - \\\n",
    "        (p['simulation_output_report.total_site_electricity_kwh']*p['elec_rate']+p['elec_fixed'])\n",
    "    \n",
    "    p['ann_energy_cost_saving'] = p['ann_gas_cost_saving']+p['ann_elec_cost_saving'] #p[['ann_gas_cost_saving','ann_elec_cost_saving']].sum(axis=1)\n",
    "    \n",
    "    if get_col_only:\n",
    "        return p['ann_energy_cost_saving']\n",
    "    else:\n",
    "        return p\n",
    "\n",
    "def get_annual_metric_ton_co2e_saving(pp, res, get_col_only=False):\n",
    "    \"\"\"\n",
    "    p: upgrade df\n",
    "    ref: reference scenario df\n",
    "    get_col_only: whether to return the computed col only or the entire upgrade df p\n",
    "    \"\"\"\n",
    "    if get_col_only:\n",
    "        p = pp.copy()\n",
    "    else:\n",
    "        p = pp\n",
    "    ref = res.set_index('building_id').reindex(p['building_id']).reset_index()\n",
    "    \n",
    "    p['ann_metric_ton_co2e_saving_gas'] = \\\n",
    "        (ref['simulation_output_report.total_site_natural_gas_therm']-\\\n",
    "         p['simulation_output_report.total_site_natural_gas_therm'])*p['gas_CO2_rate']\n",
    "    \n",
    "    p['ann_metric_ton_co2e_saving_elec'] = \\\n",
    "        (ref['simulation_output_report.total_site_electricity_kwh']-\\\n",
    "         p['simulation_output_report.total_site_electricity_kwh'])*p['elec_CO2_rate']\n",
    "    \n",
    "    p['ann_metric_ton_co2e_saving'] = p['ann_metric_ton_co2e_saving_gas'] + p['ann_metric_ton_co2e_saving_elec']\n",
    "    \n",
    "    if get_col_only:\n",
    "        return p['ann_metric_ton_co2e_saving']\n",
    "    else:\n",
    "        return p\n",
    "\n",
    "def print_metrics_report(p, has_comparative_payback=True):\n",
    "    ### (1) check for simple_payback > 100 yr or if < 0 yr\n",
    "    if len(p[~p['simple_payback'].isnull()]):\n",
    "        print(p['simple_payback'].agg(['min','median','max']))\n",
    "    spb_100 = p[p['simple_payback']>100]\n",
    "    if len(spb_100)>0:\n",
    "        print(f'    *PAYBACK1 - too large* upgrade={n} has {len(spb_100)} simple_payback>100 ' +\\\n",
    "              f'(including {len(p[p[\"simple_payback\"]==np.inf])} INF)')\n",
    "    spb_neg = p[p['simple_payback']<0]\n",
    "    if len(spb_neg)>0:\n",
    "        print(f'    *PAYBACK1 - negative*  upgrade={n} has {len(spb_neg)} simple_payback<0 ' +\\\n",
    "              '(due to negative energy cost saving)')\n",
    "\n",
    "    ### (2) check for comparative_payback > 100 yr or if < 0 yr\n",
    "    if has_comparative_payback:\n",
    "        if len(p[~p['comparative_payback'].isnull()]):\n",
    "            print(p['comparative_payback'].agg(['min','median','max']))\n",
    "        spb_100 = p[p['comparative_payback']>100]\n",
    "        if len(spb_100)>0:\n",
    "            print(f'    *PAYBACK2 - too large* upgrade={n} has {len(spb_100)} comparative_payback>100 ' +\\\n",
    "                  f'(including {len(p[p[\"comparative_payback\"]==np.inf])} INF)')\n",
    "        spb_neg = p[p['comparative_payback']<0]\n",
    "        if len(spb_neg)>0:\n",
    "            print(f'    *PAYBACK2 - negative*  upgrade={n} has {len(spb_neg)} comparative_payback<0 ' +\\\n",
    "                  '(due to negative energy cost saving)')\n",
    "\n",
    "    ### (3) check for eui==inf\n",
    "    for eui in ['pct_delta_gas_eui','pct_delta_elec_eui','pct_delta_site_eui']:\n",
    "        eui_inf = p[p[eui]==np.inf]\n",
    "        if len(eui_inf)>0:\n",
    "            print(f'       *EUI - inf* upgrade={n} has {len(eui_inf)} {eui}=INF ' +\\\n",
    "                  '(due to fuel introduction from upgrade)')\n",
    "\n",
    "    ### (4) check for neg carbon savings\n",
    "    ces_neg = p[p['ann_metric_ton_co2e_saving']<0]\n",
    "    if len(ces_neg)>0:\n",
    "        print(f'    *CARBON - negative*  upgrade={n} has {len(ces_neg)} carbon saving<0 ')\n",
    "        \n",
    "print('funcs loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### set utility rates ###\n",
    "NG_rate_multiplier = 1 # <-----\n",
    "\n",
    "if NG_rate_multiplier > 1:\n",
    "    fn_ext = f'_{NG_rate_multiplier}x_gas_prices' # file name extension to add to relevant results\n",
    "else:\n",
    "    fn_ext = ''\n",
    "\n",
    "### utility rates ###########################################\n",
    "# ref (EIA): \n",
    "# avg ComEd res elec rate 2019: $ 0.1330 /kWh\n",
    "# weighted avg IL gas rate 2019: $ 0.77183 /therm\n",
    "\n",
    "## electricity ##\n",
    "# annual fixed rates = monthly x 12\n",
    "EH_fixed = 15.70 * 12 # annual\n",
    "NEH_fixed = 14.28 *12 # annual\n",
    "# avg of summer rates (J,J,A,S) and non-summer rates\n",
    "EH_rate = (0.10273*4+0.10952*8)/12 # 0.08019, $/kWh, electric rate for electric heating customers\n",
    "NEH_rate = (0.12168*4+0.12847*8)/12 # 0.09889, $/kWh, electric rate for non-electric heating customers\n",
    "# marginal carbon emission factor:\n",
    "elec_CO2_rate = 0.000834702 # metric tons of CO2e/kWh (0.2446 tons/mbtu)\n",
    "\n",
    "## gas ##\n",
    "# annual fixed rates = monthly x 12\n",
    "GH_fixed = 45.32 * 12\n",
    "NGH_fixed = 21.51 * 12\n",
    "# variable rates\n",
    "GH_rate = 0.61648 * NG_rate_multiplier # 0.19477, $/therm, gas rate for NG heating customers\n",
    "NGH_rate = 0.56758 * NG_rate_multiplier # 0.14964, $/therm, gas rate for non-NG heating customers\n",
    "# marginal carbon emission factor:\n",
    "gas_CO2_rate = 0.00532181 # metric tons of CO2e/therm (0.0532 tons/mbtu)\n",
    "\n",
    "### upgrades that will cause utility rate change: ###########################################\n",
    "HVAC_upgrades_rate_change = {\n",
    "    17: [4,6,7], # ASHP\n",
    "    18: [4,6,7,8], # MSHP,\n",
    "}\n",
    "\n",
    "# assign rates accordingly\n",
    "Elec_heating_types = ['Electricity Baseboard','Electricity ASHP','Electricity Electric Furnace',\n",
    "                      'Electricity Electric Boiler', 'Electricity Electric Wall Furnace']\n",
    "NG_heating_types = ['Natural Gas Fuel Wall/Floor Furnace', 'Natural Gas Fuel Furnace',\n",
    "                    'Natural Gas Fuel Boiler']\n",
    "\n",
    "res['gas_rate'] = NGH_rate\n",
    "res['gas_fixed'] = NGH_fixed\n",
    "res['gas_CO2_rate'] = gas_CO2_rate\n",
    "res['elec_rate'] = NEH_rate\n",
    "res['elec_fixed'] = NEH_fixed\n",
    "res['elec_CO2_rate'] = elec_CO2_rate\n",
    "\n",
    "res.loc[(res[res['build_existing_model.hvac_heating_type_and_fuel'].isin(NG_heating_types)]).index,\n",
    "       'gas_rate'] = GH_rate\n",
    "res.loc[(res[res['build_existing_model.hvac_heating_type_and_fuel'].isin(NG_heating_types)]).index,\n",
    "       'gas_fixed'] = GH_fixed\n",
    "res.loc[(res[res['build_existing_model.hvac_heating_type_and_fuel'].isin(Elec_heating_types)]).index,\n",
    "        'elec_rate'] = EH_rate\n",
    "res.loc[(res[res['build_existing_model.hvac_heating_type_and_fuel'].isin(Elec_heating_types)]).index,\n",
    "        'elec_fixed'] = EH_fixed\n",
    "\n",
    "# assign 0 gas rates to building with no gas use \n",
    "res.loc[res['simulation_output_report.total_site_natural_gas_therm'].isin([0, np.nan]), 'gas_fixed'] = 0 \n",
    "res.loc[res['simulation_output_report.total_site_natural_gas_therm'].isin([0, np.nan]), 'gas_rate'] = 0 \n",
    "res.loc[res['simulation_output_report.total_site_electricity_kwh'].isin([0, np.nan]), 'elec_fixed'] = 0 \n",
    "res.loc[res['simulation_output_report.total_site_electricity_kwh'].isin([0, np.nan]), 'elec_rate'] = 0\n",
    "\n",
    "for col in ['gas_rate','gas_fixed','gas_CO2_rate','elec_rate','elec_fixed','elec_CO2_rate']:\n",
    "    res.loc[res['completed_status']!='Success', col] = np.nan\n",
    "\n",
    "print(f'Natural gas rate multiplier: {NG_rate_multiplier}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get baseline results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### count upgrades\n",
    "N_upgrades = 4 # <---\n",
    "export_all_upgrades_to_csv = True # <------\n",
    "\n",
    "print(f'>>> {iter_path} has {N_upgrades:,} packages')\n",
    "print(f'Natural gas rate multiplier: {NG_rate_multiplier}')\n",
    "if export_all_upgrades_to_csv:\n",
    "    print(f'    Exporting upgrades results to {combined_res_csv_path}\\n')        \n",
    "    res.to_csv(os.path.join(combined_res_csv_path, f'results_baseline{fn_ext}.csv'), index=False)\n",
    "    \n",
    "## get summary table\n",
    "summary_upgrades = []\n",
    "package_list = [11, 13, 17, 18]\n",
    "for n in package_list:\n",
    "    p = pd.read_csv(os.path.join(combined_res_csv_path,\n",
    "                                     f'package{n:02d}.csv'))\n",
    "    print(f'\\nPackage {n}')\n",
    "    p['build_existing_model.sample_weight'] = 2173432/40000\n",
    "    \n",
    "    ### get sim output at unit level\n",
    "    p = get_per_unit_sim_output_limited(p, res)\n",
    "\n",
    "    ### assign utility rates\n",
    "    p = assign_utility_rates_to_upgrade(n, p, res, HVAC_upgrades_rate_change, for_packages=True)\n",
    "    \n",
    "    ### collapse upgrade cost and lifetime cols\n",
    "    p = combine_upgrade_cost_and_lifetime(p)\n",
    "\n",
    "    ### check if upgrade has 0 successful sims\n",
    "    if len(p[p['completed_status']=='Success']) == 0:\n",
    "        print(f' * upgrade={n} has 0 successful simulations')\n",
    "\n",
    "    ### calculate metrics\n",
    "    p = add_sqft_eui(p, res)\n",
    "    EUIi = ['gas_eui_thermpersqft','elec_eui_kwhpersqft','site_eui_kbtupersqft']\n",
    "    EUIo = ['gas_eui','elec_eui','site_eui']\n",
    "    for vari, varo in zip(EUIi, EUIo):\n",
    "        p[f'pct_delta_{varo}'] = ((p[vari]-res[vari])/res[vari]*100)\n",
    "\n",
    "\n",
    "    # annual energy saving:\n",
    "    p = get_annual_gas_elec_site_energy_saving(p, res)\n",
    "\n",
    "    # annual energy cost saving:\n",
    "    p = get_annual_energy_cost_saving(p, res)\n",
    "    \n",
    "    # annual kBtu saved per upgrade cost:\n",
    "    p['ann_kbtu_saved_per_dollar'] = p['ann_mbtu_site_energy_saving'].divide(\n",
    "                            p['upgrade_cost'], axis=0)*1000\n",
    "\n",
    "    # simple payback\n",
    "    p['simple_payback'] = p['upgrade_cost']/p['ann_energy_cost_saving']\n",
    "\n",
    "    # annual metric ton carbon emission savings:\n",
    "    p = get_annual_metric_ton_co2e_saving(p, res)\n",
    "\n",
    "    ### check for neg/large paybacks, inf eui, neg carbon savings \n",
    "    print_metrics_report(p, has_comparative_payback=False)\n",
    "    \n",
    "    ### subset to only those that have been applied with the upgrades successfully:\n",
    "    upgrade_name = p['apply_upgrade.upgrade_name'].replace('',np.nan).dropna(axis=0).unique()[0]\n",
    "    p = p[p['apply_upgrade.applicable']==True].reset_index(drop=True)\n",
    "    p['package_no'] = n\n",
    "    \n",
    "    ### export upgrade results to csv \n",
    "    if export_all_upgrades_to_csv:\n",
    "        p.to_csv(os.path.join(combined_res_csv_path, f'results_package{n:02d}{fn_ext}.csv'), index=False)\n",
    "    \n",
    "    for eui in ['pct_delta_gas_eui','pct_delta_elec_eui','pct_delta_site_eui']:\n",
    "        p[eui] = p[eui].replace([np.inf, -np.inf], np.nan) # for mean calc\n",
    "        \n",
    "    ### add to summary table\n",
    "    summ = pd.DataFrame()\n",
    "    summ.loc[0,'upgrade_no'] = n\n",
    "    summ.loc[0,'upgrade_name'] = upgrade_name\n",
    "    summ.loc[0,'n_applied'] = len(p)\n",
    "    summ.loc[0,'n_success'] = len(p[p['completed_status']=='Success'])\n",
    "    summ.loc[0,'n_fail'] = len(p[p['completed_status']=='Fail'])\n",
    "    summ['pct_success'] = round(summ['n_success']/summ['n_applied']*100,3)\n",
    "\n",
    "    p = p[p['completed_status']=='Success'].reset_index(drop=True)\n",
    "    summ['mean_ann_therm_gas_saving'] = round(p['ann_therm_gas_saving'].mean(), 3)\n",
    "    summ['mean_ann_kwh_elec_saving'] = round(p['ann_kwh_elec_saving'].mean(), 3)\n",
    "    summ['mean_ann_mbtu_site_energy_saving'] = round(p['ann_mbtu_site_energy_saving'].mean(), 3)\n",
    "    summ['mean_pct_delta_gas_eui'] = round(p['pct_delta_gas_eui'].mean(), 3)\n",
    "    summ['mean_pct_delta_elec_eui'] = round(p['pct_delta_elec_eui'].mean(), 3)\n",
    "    summ['mean_pct_delta_site_eui'] = round(p['pct_delta_site_eui'].mean(), 3)\n",
    "    summ['mean_upgrade_cost'] = round(p['upgrade_cost'].mean(),2)\n",
    "    summ['mean_ann_kbtu_saved_per_dollar'] = round(p['ann_kbtu_saved_per_dollar'].mean(),3) # annual kBtu saved per upgrade cost\n",
    "    summ['mean_ann_energy_cost_saving'] = round(p['ann_energy_cost_saving'].mean(),2)\n",
    "    summ['mean_ann_metric_ton_co2e_saving'] = round(p['ann_metric_ton_co2e_saving'].mean(),3)\n",
    "\n",
    "    summ['median_simple_payback'] = round(p['simple_payback'].median(),3)\n",
    "    \n",
    "    p['simple_payback'] = p['simple_payback'].replace([np.inf, -np.inf], np.nan) # for mean calc\n",
    "    summ['pct_pos_simple_payback_actual'] = round(len(p[p['simple_payback']>=0])/len(p)*100, 3)\n",
    "    summ['mean_pos_simple_payback_actual'] = round(p.loc[p['simple_payback']>=0, 'simple_payback'].mean(),3)\n",
    "\n",
    "    # filter: min 1 cent energy cost savings **\n",
    "    min_energy_cost_saving = 0.1 # <----- **\n",
    "    summ['pct_pos_simple_payback_filtered'] = round(len(\n",
    "        p[(p['simple_payback']>=0) & (p['ann_energy_cost_saving']>=min_energy_cost_saving)]\n",
    "    )/len(p)*100, 3)\n",
    "    summ['mean_pos_simple_payback_filtered'] = round(\n",
    "        p.loc[(p['simple_payback']>=0) & (p['ann_energy_cost_saving']>=min_energy_cost_saving), \n",
    "           'simple_payback'].mean(),3)\n",
    "\n",
    "    summary_upgrades.append(summ)\n",
    "    \n",
    "summary_upgrades = pd.concat(summary_upgrades).reset_index(drop=True)\n",
    "summary_upgrades\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### export UPGRADE summary\n",
    "summary_upgrades.to_csv(os.path.join(result_path,'processed results',f'upgrades_summary{fn_ext}.csv'), index=False)\n",
    "print(f'UPGRADE summary table saved to:\\n  {os.path.join(result_path, \"processed results\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### optional - export specific upgrade parquet as csv\n",
    "save_to_csv = False # <-----\n",
    "upgrade_list = range(1, 2+1) # [8] # <----- list of upgrades to convert to csv\n",
    "\n",
    "if save_to_csv:\n",
    "    for n in upgrade_list:\n",
    "        p = pd.read_parquet(os.path.join(result_path,'upgrades',\n",
    "                                         f'upgrade={n}/results_up{n:02d}.parquet'))\n",
    "        p.to_csv(os.path.join(result_path,'upgrades',\n",
    "                                         f'upgrade={n}/results_up{n:02d}.csv'), index=False)\n",
    "        print(f'upgrade {n:02d} parquet file exported as csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Combine results by building prototypes from Elevate Energy into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) combine baseline results by non-split-level prototypes (N=12)\n",
    "print(f'Natural gas rate multiplier: {NG_rate_multiplier}')\n",
    "### add totals metrics:\n",
    "res = get_annual_totals(res)\n",
    "\n",
    "## Load prototype csv\n",
    "groups = pd.read_csv(os.path.join(result_dir,'Groups.csv'))\n",
    "print('prototypes loaded')\n",
    "\n",
    "res_proto_upgrades = []\n",
    "for i, row in groups.iterrows():\n",
    "    if row['HousingGroupName'] not in \\\n",
    "        ['Masonry All Years Split Level','Frame Post-1978 Split Level','Frame Pre-1942 Split Level']:\n",
    "        res_group_i = get_res_by_prototype(res, res, row) # <----\n",
    "        \n",
    "        ## add tags\n",
    "#         res_group_i['build_existing_model.sample_weight'] = row['Chicago Prevalence']*100/len(res_group_i)\n",
    "        res_group_i['apply_upgrade.upgrade_name'] = 'Baseline'\n",
    "        res_group_i['package_no'] = 0\n",
    "        res_group_i['HousingGroupNo'] = row['HousingGroupNo']\n",
    "        res_group_i['HousingGroupName'] = row['HousingGroupName']\n",
    "\n",
    "        res_proto_upgrades.append(res_group_i)\n",
    "\n",
    "res_proto_upgrades = pd.concat(res_proto_upgrades, axis=0).sort_values(by=['building_id'])\n",
    "display(res_proto_upgrades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) combine upgrade results by non-split-level prototypes (N=12)\n",
    "print(f'Natural gas rate multiplier: {NG_rate_multiplier}')\n",
    "\n",
    "all_proto_upgrades = []\n",
    "\n",
    "N_upgrades = 4 # <---\n",
    "package_list = [11, 13, 17, 18]\n",
    "for n in package_list:\n",
    "    p = pd.read_csv(os.path.join(combined_res_csv_path,\n",
    "                                     f'package{n:02d}.csv'))\n",
    "    print(f'\\nPackage {n}')\n",
    "    p['build_existing_model.sample_weight'] = 2173432/40000\n",
    "\n",
    "    ### get sim output at unit level\n",
    "    p = get_per_unit_sim_output_limited(p, res)\n",
    "\n",
    "    ### assign utility rates\n",
    "    p = assign_utility_rates_to_upgrade(n, p, res, HVAC_upgrades_rate_change, for_packages=True)\n",
    "\n",
    "    ### collapse upgrade cost and lifetime cols\n",
    "    p = combine_upgrade_cost_and_lifetime(p)\n",
    "\n",
    "    ### add totals metrics:\n",
    "    p = get_annual_totals(p)\n",
    "\n",
    "    ### check if upgrade has 0 successful sims\n",
    "    if len(p[p['completed_status']=='Success']) == 0:\n",
    "        print(f' * upgrade={n} has 0 successful simulations')\n",
    "\n",
    "    ### calculate metrics\n",
    "    p = add_sqft_eui(p, res)\n",
    "    EUIi = ['gas_eui_thermpersqft','elec_eui_kwhpersqft','site_eui_kbtupersqft']\n",
    "    EUIo = ['gas_eui','elec_eui','site_eui']\n",
    "    for vari, varo in zip(EUIi, EUIo):\n",
    "        p[f'pct_delta_{varo}'] = ((p[vari]-res[vari])/res[vari]*100)\n",
    "\n",
    "    # annual energy saving:\n",
    "    p = get_annual_gas_elec_site_energy_saving(p, res)\n",
    "\n",
    "    # annual energy cost saving:\n",
    "    p = get_annual_energy_cost_saving(p, res)\n",
    "    \n",
    "    # annual kBtu saved per upgrade cost:\n",
    "    p['ann_kbtu_saved_per_dollar'] = p['ann_mbtu_site_energy_saving'].divide(\n",
    "                            p['upgrade_cost'], axis=0)*1000\n",
    "\n",
    "    # simple payback\n",
    "    p['simple_payback'] = p['upgrade_cost']/p['ann_energy_cost_saving']\n",
    "\n",
    "    # annual metric ton carbon emission savings:\n",
    "    p = get_annual_metric_ton_co2e_saving(p, res)\n",
    "\n",
    "    ### check for neg/large paybacks, inf eui, neg carbon savings \n",
    "    print_metrics_report(p, has_comparative_payback=False)\n",
    "\n",
    "    ### subset to only those that have been applied with the upgrades successfully:\n",
    "    upgrade_name = p['apply_upgrade.upgrade_name'].replace('',np.nan).dropna(axis=0).unique()[0]\n",
    "    p = p[p['apply_upgrade.applicable']==True].reset_index(drop=True)\n",
    "    p['package_no'] = n\n",
    "    \n",
    "    \n",
    "    ### get results by prototype\n",
    "    for i, row in groups.iterrows():\n",
    "        if row['HousingGroupName'] not in \\\n",
    "        ['Masonry All Years Split Level','Frame Post-1978 Split Level','Frame Pre-1942 Split Level']:\n",
    "            pi = get_res_by_prototype(p, res, row) # <----\n",
    "\n",
    "            ### subset to only those that have been applied with the upgrades successfully:\n",
    "            pi = pi[pi['simulation_output_report.applicable']==True].reset_index(drop=True)\n",
    "\n",
    "            pi['HousingGroupNo'] = row[\"HousingGroupNo\"]\n",
    "            pi['HousingGroupName'] = row[\"HousingGroupName\"]\n",
    "            all_proto_upgrades.append(pi)\n",
    "\n",
    "all_proto_upgrades = pd.concat(all_proto_upgrades, axis=0).reset_index(drop=True)\n",
    "all_proto_upgrades\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (3) combine upgrade and baseline (results by non-split-level prototypes (N=12))\n",
    "cols = set(res_proto_upgrades.columns).intersection(set(all_proto_upgrades.columns))\n",
    "all_proto_upgrades = pd.concat([all_proto_upgrades, res_proto_upgrades[cols]], axis=0).reset_index(drop=True)\n",
    "\n",
    "# (4) save\n",
    "print('\"all_proto_upgrades\" df saved')\n",
    "all_proto_upgrades.to_csv(\n",
    "    os.path.join(result_path,'processed results',f'upgrades_dB{fn_ext}.csv'), index=False)\n",
    "\n",
    "display(all_proto_upgrades)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save metadata for dB\n",
    "if NG_rate_multiplier==1:\n",
    "    cols2 = sorted((set(res_proto_upgrades.columns)-set(cols)).union(\n",
    "                   set(['building_id','completed_status',\n",
    "                        'package_no','HousingGroupNo','HousingGroupName']))\n",
    "                  )\n",
    "    res_proto_meta = res_proto_upgrades[cols2]\n",
    "    res_proto_meta = res_proto_meta[res_proto_meta['completed_status']=='Success'].reset_index(drop=True)\n",
    "    \n",
    "    cols_to_drop = [x for x in res_proto_meta.columns if \n",
    "                    x.startswith('simulation_output_report.option') or\n",
    "                    x == 'simulation_output_report.upgrade_cost_usd']\n",
    "    \n",
    "    res_proto_meta = res_proto_meta.drop(cols_to_drop, axis=1)\n",
    "\n",
    "    res_proto_meta.to_csv(\n",
    "        os.path.join(result_path,'processed results',f'upgrades_dB_meta{fn_ext}.csv'), index=False)\n",
    "\n",
    "    print('\"res_proto_meta\" df saved')\n",
    "    display(res_proto_meta)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Get core bldg aggregates for Elevate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_db_from_local = True # <-----\n",
    "NG_rate_multiplier = 1 # <-----\n",
    "\n",
    "if NG_rate_multiplier > 1:\n",
    "    fn_ext = f'_{NG_rate_multiplier}x_gas_prices' # file name extension to add to relevant results\n",
    "else:\n",
    "    fn_ext = ''\n",
    "\n",
    "if load_db_from_local:\n",
    "    all_proto_upgrades = pd.read_csv(\n",
    "        os.path.join(result_path,'processed results',f'upgrades_dB{fn_ext}.csv')\n",
    "    )\n",
    "    \n",
    "    res_proto_meta = pd.read_csv(\n",
    "        os.path.join(result_path,'processed results',f'upgrades_dB_meta{fn_ext}.csv')\n",
    "    )\n",
    "    print('\"all_proto_upgrades\" and \"res_proto_meta\" loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_proto_meta1 = res_proto_meta.copy()\n",
    "res_proto_meta1['bldg_segment'] = \\\n",
    "    'SFD '+ res_proto_meta1['build_existing_model.geometry_wall_type'].replace('WoodStud', 'Frame') + ' ' + \\\n",
    "    res_proto_meta1['vintage_ee'].str[3:].str.title()\n",
    "\n",
    "\n",
    "all_proto_upgrades1 = all_proto_upgrades.join(\n",
    "    res_proto_meta1.set_index('building_id')['bldg_segment'], on = 'building_id')\n",
    "\n",
    "\n",
    "# core bldg types that Elevate is interested in:\n",
    "core_bldgs = ['SFD Frame Pre-1942', 'SFD Masonry 1942-1978', 'SFD Masonry Pre-1942']\n",
    "all_proto_upgrades1 = all_proto_upgrades1.loc[all_proto_upgrades1['bldg_segment'].isin(core_bldgs)]\n",
    "\n",
    "all_proto_upgrades1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get 2 packages from packages_02 run\n",
    "* Comprehensive - ASHP\n",
    "* Comprehensive - MSHP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path2 = os.path.join(result_dir, f'cookcnty_packages_02') # <-----\n",
    "\n",
    "if load_db_from_local:\n",
    "    all_proto_upgrades = pd.read_csv(\n",
    "        os.path.join(result_path2,'processed results',f'upgrades_dB{fn_ext}.csv')\n",
    "    )\n",
    "    \n",
    "    res_proto_meta = pd.read_csv(\n",
    "        os.path.join(result_path2,'processed results',f'upgrades_dB_meta{fn_ext}.csv')\n",
    "    )\n",
    "    print('\"all_proto_upgrades\" and \"res_proto_meta\" loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_proto_meta2 = res_proto_meta.copy()\n",
    "res_proto_meta2['bldg_segment'] = \\\n",
    "    'SFD '+ res_proto_meta2['build_existing_model.geometry_wall_type'].replace('WoodStud', 'Frame') + ' ' + \\\n",
    "    res_proto_meta2['vintage_ee'].str[3:].str.title()\n",
    "\n",
    "\n",
    "all_proto_upgrades2 = all_proto_upgrades.join(\n",
    "    res_proto_meta2.set_index('building_id')['bldg_segment'], on = 'building_id')\n",
    "\n",
    "\n",
    "# core bldg types that Elevate is interested in:\n",
    "core_bldgs = ['SFD Frame Pre-1942', 'SFD Masonry 1942-1978', 'SFD Masonry Pre-1942']\n",
    "all_proto_upgrades2 = all_proto_upgrades2.loc[all_proto_upgrades2['bldg_segment'].isin(core_bldgs)]\n",
    "\n",
    "all_proto_upgrades2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combine packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upgrades_to_retrieve = ['Comprehensive - ASHP', 'Comprehensive - MSHP'] # <----\n",
    "\n",
    "all_proto_upgrades2 = all_proto_upgrades2[\n",
    "    all_proto_upgrades2['apply_upgrade.upgrade_name'].isin(upgrades_to_retrieve)]\n",
    "\n",
    "# combine with other packages\n",
    "all_proto_upgrades2 = pd.concat([\n",
    "    all_proto_upgrades1,\n",
    "    all_proto_upgrades2\n",
    "], axis=0)\n",
    "\n",
    "# check upgrades:\n",
    "print('Packages combined:')\n",
    "all_proto_upgrades2['apply_upgrade.upgrade_name'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filter and get baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get package-specific baseline, remove generic baseline\n",
    "upgrade_list = [x for x in all_proto_upgrades2['apply_upgrade.upgrade_name'].unique() if x != 'Baseline']\n",
    "    \n",
    "\n",
    "# query package-specific baselines\n",
    "upgrade_spec_baselines = []\n",
    "for up in upgrade_list:\n",
    "    applicable_bldgs = all_proto_upgrades2.loc[all_proto_upgrades2['apply_upgrade.upgrade_name']==up,\n",
    "                                               'building_id']\n",
    "    \n",
    "    baseline_up = all_proto_upgrades2.loc[(all_proto_upgrades2['apply_upgrade.upgrade_name']=='Baseline') & \n",
    "                                          (all_proto_upgrades2['building_id'].isin(applicable_bldgs))\n",
    "                                         ]\n",
    "    baseline_up['apply_upgrade.upgrade_name'] += ': '+up\n",
    "    \n",
    "    upgrade_spec_baselines.append(baseline_up)\n",
    "    \n",
    "# remove generic baseline and combine\n",
    "upgrade_spec_baselines.append(\n",
    "    all_proto_upgrades2.loc[all_proto_upgrades2['apply_upgrade.upgrade_name']!='Baseline']\n",
    ")\n",
    "\n",
    "all_proto_upgrades2 = pd.concat(upgrade_spec_baselines, axis=0)\n",
    "del upgrade_spec_baselines\n",
    "\n",
    "# check that package-specific baselines exist\n",
    "all_proto_upgrades2['apply_upgrade.upgrade_name'].value_counts().sort_index()\n",
    "                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    'ann_gas_cost_saving': 'Ann Gas Cost Saving',\n",
    "    'ann_elec_cost_saving': 'Ann Elec Cost Saving',\n",
    "    'ann_energy_cost_saving': 'Annual Utility Bill Savings',\n",
    "    \n",
    "    'ann_therm_gas_saving': 'Ann Therm Gas Saving', \n",
    "    'ann_kwh_elec_saving': 'Ann Kwh Elec Saving',\n",
    "    'ann_mbtu_site_energy_saving': 'Ann Mbtu Site Energy Saving',\n",
    "    'ann_metric_ton_co2e_saving': 'Ann Metric Ton Co2E Saving',\n",
    "    'pct_delta_site_eui': 'Pct Delta Site Eui',\n",
    "    \n",
    "    'simulation_output_report.total_site_natural_gas_therm': 'Ann Gas Use (Therms)',\n",
    "    'simulation_output_report.total_site_electricity_kwh': 'Ann Elec Use (kWh)',\n",
    "    'simulation_output_report.total_site_energy_mbtu': 'Ann Site Energy (mmBtu)',\n",
    "    \n",
    "    'ann_gas_cost': 'Ann Gas Cost',\n",
    "    'ann_elec_cost': 'Ann Elec Cost',\n",
    "    'ann_energy_cost': 'Ann Energy Cost',\n",
    "    'ann_metric_ton_co2e': 'Ann Metric Ton Co2E',\n",
    "    'site_eui_kbtupersqft': 'Site Eui',\n",
    "    'upgrade_cost': 'Upgrade Cost',\n",
    "} # per unit\n",
    "\n",
    "# get count\n",
    "count = all_proto_upgrades2.groupby(['apply_upgrade.upgrade_name','bldg_segment'])[\n",
    "    'building_id'].count().rename('count').to_frame()\n",
    "\n",
    "# for each metric, get [P25, avg, median, P75]\n",
    "all_proto_summ = all_proto_upgrades2.groupby(['apply_upgrade.upgrade_name','bldg_segment'])[\n",
    "    list(metrics.keys())].agg([\n",
    "    'min',\n",
    "    lambda x: x.quantile(0.25),\n",
    "    'mean',\n",
    "    'median',\n",
    "    lambda x: x.quantile(0.75),\n",
    "    'max',\n",
    "])\n",
    "\n",
    "# rename cols\n",
    "all_proto_summ = all_proto_summ.rename(columns = metrics, level=0)\n",
    "\n",
    "all_proto_summ = all_proto_summ.rename(columns = {\n",
    "    'min': 'Min.',\n",
    "    '<lambda_0>': 'Percentile (25) of',\n",
    "    'mean': 'Avg.',\n",
    "    'median': 'Median',\n",
    "    '<lambda_1>': 'Percentile (75) of',\n",
    "    'max': 'Max.',\n",
    "}, level=1)\n",
    "\n",
    "all_proto_summ.columns = [\" \".join(x) for x in all_proto_summ.columns.swaplevel().ravel()]\n",
    "\n",
    "# combine and transpose\n",
    "all_proto_summ = pd.concat([count, all_proto_summ], axis=1).transpose()\n",
    "del count\n",
    "\n",
    "# export\n",
    "all_proto_summ.to_csv(\n",
    "    os.path.join(result_path,'processed results', 'summary_elevate_core_bldgs_sfd.csv'), \n",
    "    index=True)\n",
    "\n",
    "all_proto_summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Get PACKAGE results by building prototypes from Elevate Energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_all_upgrades_and_export_as_csv = True # <------ used to plot distributions\n",
    "\n",
    "#### count upgrades\n",
    "N_upgrades = 4 # <---\n",
    "\n",
    "print(f'Natural gas rate multiplier: {NG_rate_multiplier}')\n",
    "## (1) Load prototype csv\n",
    "groups2 = pd.read_csv(os.path.join(result_dir,'Groups.csv'))\n",
    "groups2 = groups2.drop(['Non-normalized gas usage','Non-normalized elec. usage'], axis=1)\n",
    "chars_to_map = groups2[['HousingGroupNo','HousingGroupName','Stories','WallType','Vintage']]\n",
    "print('prototypes loaded.')\n",
    "\n",
    "Metric_map1 = {'count': '',\n",
    "               'mean_gas_eui therm_per_sqft': 'gas_eui_thermpersqft',\n",
    "               'mean_elec_eui kwh_per_sqft': 'elec_eui_kwhpersqft',\n",
    "               'mean_site_eui kbtu_per_sqft': 'site_eui_kbtupersqft'\n",
    "              }\n",
    "\n",
    "### (2) get baseline results\n",
    "for i, row in chars_to_map.iterrows():\n",
    "    res_i = get_res_by_prototype(res, res, row) # <----\n",
    "    \n",
    "    for metric, res_var in Metric_map1.items():\n",
    "        if metric == 'count':\n",
    "            groups2.loc[i, 'count'] = len(res_i)\n",
    "        else:\n",
    "            groups2.loc[i, metric] = res_i[res_var].mean()\n",
    "\n",
    "groups2.columns = pd.MultiIndex.from_product([['Baseline'], groups2.columns])\n",
    "print('Prototype baseline results copied.')\n",
    "print(f'Number of buildings simulated: {len(res)}')\n",
    "N_baseline = len(groups2.columns)\n",
    "\n",
    "if combine_all_upgrades_and_export_as_csv:\n",
    "    all_proto_upgrades = []\n",
    "\n",
    "### (3) add upgrades results\n",
    "package_list = [11, 13, 17, 18]\n",
    "for n in package_list:\n",
    "    nf = f'0{n}' if n<10 else n\n",
    "    p = pd.read_csv(os.path.join(combined_res_csv_path,\n",
    "                                     f'package{nf}.csv'))\n",
    "    print(f'\\nPackage {n}')\n",
    "    p['build_existing_model.sample_weight'] = 2173432/40000\n",
    "    \n",
    "    ### get sim output at unit level\n",
    "    p = get_per_unit_sim_output_limited(p, res)\n",
    "\n",
    "    ### assign utility rates\n",
    "    p = assign_utility_rates_to_upgrade(n, p, res, HVAC_upgrades_rate_change, for_packages=True)\n",
    "    \n",
    "    ### collapse upgrade cost and lifetime cols\n",
    "    p = combine_upgrade_cost_and_lifetime(p)\n",
    "\n",
    "    ### check if upgrade has 0 successful sims\n",
    "    if len(p[p['completed_status']=='Success']) == 0:\n",
    "        print(f' * upgrade={n} has 0 successful simulations')\n",
    "\n",
    "    ### calculate metrics\n",
    "    p = add_sqft_eui(p, res)\n",
    "    EUIi = ['gas_eui_thermpersqft','elec_eui_kwhpersqft','site_eui_kbtupersqft']\n",
    "    EUIo = ['gas_eui','elec_eui','site_eui']\n",
    "    for vari, varo in zip(EUIi, EUIo):\n",
    "        p[f'pct_delta_{varo}'] = ((p[vari]-res[vari])/res[vari]*100)\n",
    "\n",
    "\n",
    "    # annual energy saving:\n",
    "    p = get_annual_gas_elec_site_energy_saving(p, res)\n",
    "\n",
    "    # annual energy cost saving:\n",
    "    p = get_annual_energy_cost_saving(p, res)\n",
    "    \n",
    "    # annual kBtu saved per upgrade cost:\n",
    "    p['ann_kbtu_saved_per_dollar'] = p['ann_mbtu_site_energy_saving'].divide(\n",
    "                            p['upgrade_cost'], axis=0)*1000\n",
    "\n",
    "    # simple payback\n",
    "    p['simple_payback'] = p['upgrade_cost']/p['ann_energy_cost_saving']\n",
    "\n",
    "    # annual metric ton carbon emission savings:\n",
    "    p = get_annual_metric_ton_co2e_saving(p, res)\n",
    "\n",
    "    ### check for neg/large paybacks, inf eui, neg carbon savings \n",
    "    print_metrics_report(p, has_comparative_payback=False)\n",
    "    \n",
    "    ### subset to only those that have been applied with the upgrades successfully:\n",
    "    upgrade_name = p['apply_upgrade.upgrade_name'].replace('',np.nan).dropna(axis=0).unique()[0]\n",
    "    p = p[p['apply_upgrade.applicable']==True].reset_index(drop=True)\n",
    "    p['package_no'] = n\n",
    "    \n",
    "    ### get results by prototype\n",
    "    for i, row in chars_to_map.iterrows():\n",
    "        pi = get_res_by_prototype(p, res, row) # <----\n",
    "        \n",
    "        ### subset to only those that have been applied with the upgrades successfully:\n",
    "        pi = pi[pi['simulation_output_report.applicable']==True].reset_index(drop=True)\n",
    "        \n",
    "        if combine_all_upgrades_and_export_as_csv:\n",
    "            pi['HousingGroupNo'] = row[\"HousingGroupNo\"]\n",
    "            pi['HousingGroupName'] = row[\"HousingGroupName\"]\n",
    "            all_proto_upgrades.append(pi)\n",
    "        \n",
    "        for var in ['pct_delta_gas_eui','pct_delta_elec_eui','pct_delta_site_eui','ann_metric_ton_co2e_saving']:\n",
    "            pi[var] = pi[var].replace([np.inf, -np.inf], np.nan) # for mean calc\n",
    "            groups2.loc[i, ((f'mean_{var}'),(f'pkg{nf}: {upgrade_name}'))] = round(pi[var].replace(\n",
    "                [np.inf, -np.inf], np.nan).mean(), 3)\n",
    "        for var in ['upgrade_cost', 'ann_kbtu_saved_per_dollar','ann_energy_cost_saving']:\n",
    "            pi[var] = pi[var].replace([np.inf, -np.inf], np.nan) # for mean calc\n",
    "            groups2.loc[i, ((f'mean_{var}'),(f'pkg{nf}: {upgrade_name}'))] = round(pi[var].mean(), 2)\n",
    "        for var in ['simple_payback']:\n",
    "            n_cp = len(pi[~pi[var].isnull()])\n",
    "            if n_cp>0:\n",
    "                groups2.loc[i, ((f'median_{var}'),(f'pkg{nf}: {upgrade_name}'))] = round(pi[var].median(), 2)\n",
    "                pi[var] = pi[var].replace([np.inf, -np.inf], np.nan) # for mean calc\n",
    "                \n",
    "                # filter: min 1 cent energy cost savings **\n",
    "                min_energy_cost_saving = 0.1 # <----- ** \n",
    "                groups2.loc[i, ((f'pct_pos_{var}'),(f'pkg{nf}: {upgrade_name}'))] = round(len(\n",
    "                    pi[(p[var]>=0) & (pi['ann_energy_cost_saving']>=min_energy_cost_saving)]\n",
    "                    )/n_cp*100, 3)\n",
    "                groups2.loc[i, ((f'mean_pos_{var}'),(f'pkg{nf}: {upgrade_name}'))] = round(\n",
    "                    pi.loc[(p[var]>=0) & (p['ann_energy_cost_saving']>=min_energy_cost_saving),var].mean(), 2)\n",
    "            else:\n",
    "                groups2.loc[i, ((f'median_{var}'),(f'pkg{nf}: {upgrade_name}'))] = np.nan\n",
    "                groups2.loc[i, ((f'pct_pos_{var}'),(f'pkg{nf}: {upgrade_name}'))] = np.nan\n",
    "                groups2.loc[i, ((f'mean_pos_{var}'),(f'pkg{nf}: {upgrade_name}'))] = np.nan\n",
    "        \n",
    "if combine_all_upgrades_and_export_as_csv:\n",
    "    all_proto_upgrades = pd.concat(all_proto_upgrades).reset_index(drop=True).replace('',np.nan).dropna(axis=1, how='all')\n",
    "    all_proto_upgrades.to_csv(os.path.join(result_path,'processed results',f'all_upgrades_by_prototype_combined{fn_ext}.csv'), index=False)\n",
    "    print(f'\\nall {len(package_list)} UPGRADEs are combined and saved to:\\n  {os.path.join(result_path, \"processed results\")}')            \n",
    "\n",
    "# split to sort\n",
    "groups_upgrades = groups2.iloc[:, N_baseline:].sort_index(axis=1, level=[0,1]) # in upgrades section, sort by col indices\n",
    "groups2 = pd.concat([groups2.iloc[:, :N_baseline],groups_upgrades], axis=1)              \n",
    "groups2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### export prototype UPGRADE summary\n",
    "groups2.to_csv(os.path.join(result_path,'processed results',f'upgrades_prototype_results{fn_ext}.csv'), index=False)\n",
    "print(f'UPGRADE summary table saved to:\\n  {os.path.join(result_path, \"processed results\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Get UPGRADE results for Chicago total stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### count upgrades\n",
    "N_upgrades = 4\n",
    "\n",
    "print(f'Natural gas rate multiplier: {NG_rate_multiplier}')\n",
    "## (1) Load prototype csv\n",
    "groups3 = pd.read_csv(os.path.join(result_dir,'Groups.csv'))\n",
    "groups3 = groups3.drop(['Non-normalized gas usage','Non-normalized elec. usage'], axis=1)\n",
    "chars_to_map = groups3[['HousingGroupNo','HousingGroupName','Stories','WallType','Vintage']]\n",
    "print('prototypes loaded.')\n",
    "\n",
    "groups3.columns = pd.MultiIndex.from_product([['Baseline'], groups3.columns])\n",
    "print('Prototype baseline results copied.')\n",
    "print(f'Number of buildings simulated: {len(res)}')\n",
    "N_baseline = len(groups3.columns)\n",
    "\n",
    "### (3) add upgrades results\n",
    "package_list = [11, 13, 17, 18]\n",
    "for n in package_list:\n",
    "    nf = f'0{n}' if n<10 else n\n",
    "    p = pd.read_csv(os.path.join(combined_res_csv_path,\n",
    "                                     f'package{nf}.csv'))\n",
    "    print(f'\\nPackage {n}')\n",
    "    p['build_existing_model.sample_weight'] = 2173432/40000\n",
    "    \n",
    "    ### get sim output at unit level\n",
    "    p = get_per_unit_sim_output_limited(p, res)\n",
    "\n",
    "    ### assign utility rates\n",
    "    p = assign_utility_rates_to_upgrade(n, p, res, HVAC_upgrades_rate_change, for_packages=True)\n",
    "    \n",
    "    ### collapse upgrade cost and lifetime cols\n",
    "    p = combine_upgrade_cost_and_lifetime(p)\n",
    "\n",
    "    ### check if upgrade has 0 successful sims\n",
    "    if len(p[p['completed_status']=='Success']) == 0:\n",
    "        print(f' * upgrade={n} has 0 successful simulations')\n",
    "\n",
    "    ### calculate metrics\n",
    "    p = add_sqft_eui(p, res)\n",
    "    EUIi = ['gas_eui_thermpersqft','elec_eui_kwhpersqft','site_eui_kbtupersqft']\n",
    "    EUIo = ['gas_eui','elec_eui','site_eui']\n",
    "    for vari, varo in zip(EUIi, EUIo):\n",
    "        p[f'pct_delta_{varo}'] = ((p[vari]-res[vari])/res[vari]*100)\n",
    "\n",
    "\n",
    "    # annual energy saving:\n",
    "    p = get_annual_gas_elec_site_energy_saving(p, res)\n",
    "\n",
    "    # annual energy cost saving:\n",
    "    p = get_annual_energy_cost_saving(p, res)\n",
    "\n",
    "    # annual metric ton carbon emission savings:\n",
    "    p = get_annual_metric_ton_co2e_saving(p, res)\n",
    "\n",
    "    ### subset to only those that have been applied with the upgrades successfully:\n",
    "    upgrade_name = p['apply_upgrade.upgrade_name'].replace('',np.nan).dropna(axis=0).unique()[0]\n",
    "    p = p[p['apply_upgrade.applicable']==True].reset_index(drop=True)\n",
    "    p['package_no'] = n\n",
    "    \n",
    "    ### get results by prototype\n",
    "    for i, row in chars_to_map.iterrows():\n",
    "        pi = get_res_by_prototype(p, res, row) # <----\n",
    "        \n",
    "        ### subset to only those that have been applied with the upgrades successfully:\n",
    "        pi = pi[pi['simulation_output_report.applicable']==True].reset_index(drop=True)\n",
    "\n",
    "        for var in ['ann_mbtu_site_energy_saving','ann_therm_gas_saving', 'ann_kwh_elec_saving', \n",
    "                    'ann_metric_ton_co2e_saving']:\n",
    "            pi[var] = pi[var].replace([np.inf, -np.inf], np.nan) # for mean calc\n",
    "            groups3.loc[i, ((f'mean_{var}'),(f'pkg{nf}: {upgrade_name}'))] = round(pi[var].mean(), 3)\n",
    "            \n",
    "        for var in ['upgrade_cost','ann_gas_cost_saving','ann_elec_cost_saving', 'ann_energy_cost_saving']:\n",
    "            pi[var] = pi[var].replace([np.inf, -np.inf], np.nan) # for mean calc\n",
    "            groups3.loc[i, ((f'mean_{var}'),(f'pkg{nf}: {upgrade_name}'))] = round(pi[var].mean(), 2)\n",
    "\n",
    "# split to sort\n",
    "groups_upgrades = groups3.iloc[:, N_baseline:].sort_index(axis=1, level=[0,1]) # in upgrades section, sort by col indices\n",
    "groups3 = pd.concat([groups3.iloc[:, :N_baseline],groups_upgrades], axis=1)              \n",
    "groups3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivot results for Chicago total stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nchicago = 273742 # no of sfd in Chicago\n",
    "Wtchicago = groups3.loc[:,[('Baseline', 'HousingGroupName'),('Baseline', 'Chicago Prevalence')]\n",
    "                       ]['Baseline'].set_index('HousingGroupName')\n",
    "\n",
    "## add 'Chicago avg' and 'Chicago total'\n",
    "groups_total = groups3.set_index(('Baseline', 'HousingGroupName')).drop('Baseline', level=0, axis=1)\n",
    "groups_total.index.name = groups_total.index.name[1]\n",
    "groups_total = groups_total.stack(level=0).stack().unstack(level=0)\n",
    "groups_total['Chicago avg'] = np.where(np.isnan(groups_total),0,groups_total).dot(\n",
    "    np.where(np.isnan(Wtchicago),0,Wtchicago)) # np.dot() ignoring nan\n",
    "groups_total['Chicago total'] = groups_total['Chicago avg']*Nchicago\n",
    "\n",
    "## add upgrade names\n",
    "upgrade_name_map = summary_upgrades[['upgrade_no','upgrade_name']].copy()\n",
    "upgrade_name_map.loc[:,'upgrade'] = upgrade_name_map['upgrade_no'].astype(int)\n",
    "# upgrade_name_map.loc[:,'upgrade'] = 'upg' + \\\n",
    "#     upgrade_name_map['upgrade_no'].astype(int).astype(str).str.rjust(2,'0')\n",
    "upgrade_name_map = upgrade_name_map.set_index('upgrade')['upgrade_name']\n",
    "\n",
    "groups_total = groups_total.reset_index().rename({'level_0':'metrics','level_1':'upgrade_no'}, axis=1)\n",
    "groups_total['upgrade_no'] = groups_total['upgrade_no'].str[3:5].astype(int)\n",
    "groups_total['upgrade_name'] = groups_total['upgrade_no'].map(upgrade_name_map)\n",
    "groups_total = groups_total.set_index(['metrics','upgrade_no','upgrade_name']).sort_index().reset_index()\n",
    "\n",
    "print(f'Natural gas rate multiplier: {NG_rate_multiplier}')\n",
    "groups_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### export prototype UPGRADE results for Chicago total stock\n",
    "groups_total.to_csv(\n",
    "    os.path.join(result_path,\n",
    "                 'processed results',f'upgrades_prototype_chicago_total{fn_ext}.csv'), index=False)\n",
    "print(f'UPGRADE total Chicago saved to:\\n  {os.path.join(result_path, \"processed results\")}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get baseline totals for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Baseline total metrics:')\n",
    "\n",
    "### (1) ResStock simulation total\n",
    "print(f'  ** Cook County, total from simulation of {len(res[res[\"completed_status\"]==\"Success\"])} valid SFD')\n",
    "display(res[['simulation_output_report.total_site_natural_gas_therm', \n",
    "             'simulation_output_report.total_site_electricity_kwh',\n",
    "             'simulation_output_report.total_site_energy_mbtu',\n",
    "             'ann_gas_cost',\n",
    "             'ann_elec_cost',\n",
    "             'ann_energy_cost',\n",
    "             'ann_metric_ton_co2e_gas',\n",
    "             'ann_metric_ton_co2e_elec',\n",
    "             'ann_metric_ton_co2e'\n",
    "            ]].sum())\n",
    "\n",
    "Metric_map2 = {'mean gas': 'simulation_output_report.total_site_natural_gas_therm',\n",
    "               'mean elec': 'simulation_output_report.total_site_electricity_kwh',\n",
    "               'mean site': 'simulation_output_report.total_site_energy_mbtu',\n",
    "               'mean_gas_cost': 'ann_gas_cost',\n",
    "               'mean_elec_cost': 'ann_elec_cost',\n",
    "               'mean_energy_cost': 'ann_energy_cost',\n",
    "               'mean_co2_gas': 'ann_metric_ton_co2e_gas',\n",
    "               'mean_co2_elec': 'ann_metric_ton_co2e_elec',\n",
    "               'mean_co2': 'ann_metric_ton_co2e'\n",
    "              } # metric: res_var\n",
    "\n",
    "for i, row in groups.iterrows():\n",
    "    res_group_i = get_res_by_prototype(res, res, row) # <----\n",
    "    \n",
    "    for metric, res_var in Metric_map2.items():\n",
    "        groups.loc[i, metric] = res_group_i[res_var].mean()\n",
    "\n",
    "        \n",
    "### (2) Chicago total (15 SFD prototypes)\n",
    "Nchicago = 273742 # no of sfd in Chicago\n",
    "print(f'  ** Chicago, total from {Nchicago} x Chicago avg from 15 SFD prototypes (including split-levels)')\n",
    "Chicago_avg = pd.Series(\n",
    "    np.dot(groups[Metric_map2.keys()].transpose(), groups['Chicago Prevalence'])\n",
    "    / groups['Chicago Prevalence'].sum(), \n",
    "    index = [str(var).replace('mean','total') for var in Metric_map2.keys()]\n",
    ")\n",
    "\n",
    "Chicago_total = Chicago_avg * Nchicago\n",
    "display(Chicago_total)\n",
    "\n",
    "\n",
    "### (3) Chicago total, excluding split-levels (13 SFD prototypes)\n",
    "idx = ~groups['HousingGroupName'].isin(['Masonry All Years Split Level',\n",
    "                                        'Frame Post-1978 Split Level',\n",
    "                                         'Frame Pre-1942 Split Leve'])\n",
    "\n",
    "sfd_nonsplitlevel_prev = groups.loc[idx, 'Chicago Prevalence'].sum()\n",
    "\n",
    "Nchicago2 = 273742*sfd_nonsplitlevel_prev # no of sfd in Chicago\n",
    "print(f'  ** Chicago, total from {Nchicago2:.0f} x Chicago avg from 13 SFD prototypes (excluding split-levels: '\n",
    "      f'{(1-sfd_nonsplitlevel_prev)*100:.2f}%)')\n",
    "Chicago_avg2 = pd.Series(\n",
    "    np.dot(groups.loc[idx, Metric_map2.keys()].transpose(), groups.loc[idx, 'Chicago Prevalence'])\n",
    "    / groups.loc[idx, 'Chicago Prevalence'].sum(), \n",
    "    index = [str(var).replace('mean','total') for var in Metric_map2.keys()]\n",
    ")\n",
    "\n",
    "Chicago_total2 = Chicago_avg2 * Nchicago2\n",
    "display(Chicago_total2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Visualize UPGRADE prototype summary \n",
    "#### 2.3.1. plot mean metrics values\n",
    "Run cell below to load df for plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_df_for_plot_below_from_file = False # <-----\n",
    "    \n",
    "if load_df_for_plot_below_from_file:\n",
    "    NG_rate_multiplier = 1 # 1 or 3 <----- This controls what to plot in both '2.3.1.' and '2.3.2.' plots\n",
    " \n",
    "    if NG_rate_multiplier > 1:\n",
    "        fn_ext = f'_{NG_rate_multiplier}x_gas_prices' # file name extension to add to relevant results\n",
    "    else:\n",
    "        fn_ext = ''\n",
    "    \n",
    "    groups2 = pd.read_csv(os.path.join(result_path,'processed results',f'upgrades_prototype_results{fn_ext}.csv'),\n",
    "                         header=[0, 1])\n",
    "    \n",
    "    print(f'\"groups2{fn_ext}\" df loaded from file.')\n",
    "    display(groups2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### other metrics to consider:\n",
    "# monthly utility bills (gas + elec)\n",
    "# carbon savings (require timeseries results)\n",
    "\n",
    "zoom_in_plots = False # <-------\n",
    "\n",
    "zoom_in_xlimits = {\n",
    "    'mean_pct_delta_gas_eui': [None, None],\n",
    "    'mean_pct_delta_elec_eui': [None, None],\n",
    "    'mean_pct_delta_site_eui': [-25, None],\n",
    "    'mean_upgrade_cost': [None, 10000],\n",
    "    'mean_ann_kbtu_saved_per_dollar': [None, 500],\n",
    "    'mean_ann_energy_cost_saving': [None, 2000],\n",
    "    'mean_ann_metric_ton_co2e_saving': [None, 20],\n",
    "    'median_simple_payback': [-70, 70],\n",
    "}\n",
    "\n",
    "# create subfolder for plots:\n",
    "plot_path1 = os.path.join(plot_path, 'mean_values_by_prototype')\n",
    "if not os.path.exists(plot_path1):\n",
    "    os.mkdir(plot_path1)\n",
    "print(f'plot dir: {plot_path1}\\n')\n",
    "\n",
    "title_ext = '' if fn_ext == '' else f' ({fn_ext.replace(\"_\",\" \").lstrip()})'\n",
    "\n",
    "if NG_rate_multiplier == 1:\n",
    "    para_labels = {\n",
    "        'mean_pct_delta_gas_eui': 'Mean percent change from baseline in gas use intensity (therm/sqft)',\n",
    "        'mean_pct_delta_elec_eui': 'Mean percent change from baseline in electricity use intensity (kWh/sqft)',\n",
    "        'mean_pct_delta_site_eui': 'Mean percent change from baseline in site energy use intensity (kBtu/sqft)',\n",
    "        'mean_upgrade_cost': 'Mean upgrade capital cost ($)',\n",
    "        'mean_ann_kbtu_saved_per_dollar': 'Mean annual site energy saving per upgrade cost (kBtu/$)',\n",
    "        'mean_ann_energy_cost_saving': f'Mean annual energy cost saving{title_ext} ($)',\n",
    "        'mean_ann_metric_ton_co2e_saving': f'Mean annual carbon emission saving (metric ton CO₂e)',\n",
    "        'median_simple_payback': f'Median simple payback period{title_ext} (yr)',\n",
    "        'mean_pos_simple_payback': f'Mean positive simple payback period{title_ext} (yr)',\n",
    "    }\n",
    "else:\n",
    "    para_labels = {\n",
    "        'mean_ann_energy_cost_saving': f'Mean annual energy cost saving{title_ext} ($)',\n",
    "        'median_simple_payback': f'Median simple payback period{title_ext} (yr)',\n",
    "        'mean_pos_simple_payback': f'Mean positive simple payback period{title_ext} (yr)',\n",
    "    }\n",
    "\n",
    "    \n",
    "for i, para_to_plot in enumerate(para_labels.keys(),1):\n",
    "    \n",
    "    zoom_ext = ''\n",
    "    if zoom_in_plots:\n",
    "        if len(list(x for x in zoom_in_xlimits[para_to_plot] if x is not None))>0:\n",
    "            zoom_ext = '_zoomed'\n",
    "    \n",
    "    print(f'>> {i}. plotting {para_to_plot}{fn_ext}{zoom_ext}...')\n",
    "    para_label = para_labels[para_to_plot]\n",
    "\n",
    "    idx = groups2.loc[:,(('Baseline'),('HousingGroupNo'))].astype(str) +'. '+\\\n",
    "          groups2.loc[:,(('Baseline'),('HousingGroupName'))]\n",
    "    UPi = groups2.set_index(idx)[para_to_plot]\n",
    "    xmin = UPi.replace([np.inf, -np.inf], np.nan).min().min()\n",
    "    xmax = UPi.replace([np.inf, -np.inf], np.nan).max().max()\n",
    "\n",
    "    fig, ax = plt.subplots(ncols=1, nrows=1, sharex=True, sharey=True, figsize=(14, 14))\n",
    "\n",
    "    ### Group 1: Intensive, fuel-agnostic upgrades (upg01-upg21)\n",
    "    # Group 1A: (upg01-upg10) N=10\n",
    "    UPi.plot(kind='barh', width=0.8, ax=ax)\n",
    "    ax.xaxis.grid(True)\n",
    "    if (para_to_plot[-3:]=='eui') & (xmin < -50):\n",
    "        ax.axvline(x=-50, linestyle='--', color='darkred')\n",
    "    ax.set_title(para_label, fontsize=15, y=1)\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend(handles[::-1], labels[::-1], ncol=1, loc='center left', bbox_to_anchor=(1, 0.5), fontsize='medium')\n",
    "    ax.margins(y=0)\n",
    "    \n",
    "    if zoom_in_plots:\n",
    "        [xmin, xmax] = zoom_in_xlimits[para_to_plot]\n",
    "        if xmin is not None:\n",
    "            ax.set_xlim(left = xmin)\n",
    "        if xmax is not None:\n",
    "            ax.set_xlim(right=xmax)\n",
    "            \n",
    "    if para_to_plot in ['median_simple_payback', 'mean_pos_simple_payback']:\n",
    "        if xmax >= 150:\n",
    "            ax.set_xlim(0,150)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    filename = f'{iter_path}-comparison_{para_to_plot}{fn_ext}.pdf'\n",
    "    fig.savefig(os.path.join(plot_path1, filename),\n",
    "                bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2. plot mean values for Chicago avg per SFD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wtchicago = groups2.loc[:,[('Baseline', 'HousingGroupName'),('Baseline', 'Chicago Prevalence')]\n",
    "                       ]['Baseline'].set_index('HousingGroupName')\n",
    "\n",
    "## add 'Chicago avg' and 'Chicago total'\n",
    "groups_avg = groups2.set_index(('Baseline', 'HousingGroupName')).drop('Baseline', level=0, axis=1)\n",
    "groups_avg.index.name = groups_avg.index.name[1]\n",
    "groups_avg = groups_avg.stack(level=0).stack().unstack(level=0)\n",
    "groups_avg['Chicago avg'] = np.where(np.isnan(groups_avg),0,groups_avg).dot(\n",
    "    np.where(np.isnan(Wtchicago),0,Wtchicago)) # np.dot() ignoring nan\n",
    "\n",
    "## add upgrade names\n",
    "upgrade_name_map = summary_upgrades[['upgrade_no','upgrade_name']].copy()\n",
    "upgrade_name_map.loc[:,'upgrade'] = upgrade_name_map['upgrade_no'].astype(int)\n",
    "# upgrade_name_map.loc[:,'upgrade'] = 'upg' + \\\n",
    "#     upgrade_name_map['upgrade_no'].astype(int).astype(str).str.rjust(2,'0')\n",
    "upgrade_name_map = upgrade_name_map.set_index('upgrade')['upgrade_name']\n",
    "\n",
    "groups_avg = groups_avg.reset_index().rename({'level_0':'metrics','level_1':'upgrade_no'}, axis=1)\n",
    "groups_avg['upgrade_no'] = groups_avg['upgrade_no'].str[3:5].astype(int)\n",
    "groups_avg['upgrade_name'] = groups_avg['upgrade_no'].map(upgrade_name_map)\n",
    "groups_avg = groups_avg.set_index(['metrics','upgrade_no','upgrade_name']).sort_index().reset_index()\n",
    "\n",
    "### save a copy\n",
    "groups_avg.to_csv(os.path.join(result_path,\n",
    "                               'processed results',\n",
    "                               f'upgrades_prototype_chicago_avg_results{fn_ext}.csv'),\n",
    "                  index=True)\n",
    "print(f'Natural gas rate multiplier: {NG_rate_multiplier}')\n",
    "groups_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_to_plot = 'Chicago avg' # <------\n",
    "\n",
    "N_upgrades=19\n",
    "upgrade_sets = {\n",
    "    'Packages': range(6, N_upgrades+6),\n",
    "}\n",
    "upgrade_set_colors = {\n",
    "    'Packages': 'tab:blue',\n",
    "}\n",
    "\n",
    "# create subfolder for plots:\n",
    "plot_path2 = os.path.join(plot_path, 'mean_values_chicago_avg')\n",
    "if not os.path.exists(plot_path2):\n",
    "    os.mkdir(plot_path2)\n",
    "print(f'plot dir: {plot_path2}\\n')\n",
    "\n",
    "if NG_rate_multiplier == 1: \n",
    "    metrics_to_plot = groups_avg['metrics'].unique()\n",
    "else:\n",
    "    metrics_to_plot = ['mean_ann_energy_cost_saving', 'median_simple_payback']\n",
    "    \n",
    "for metric in metrics_to_plot:\n",
    "    title_ext = '' if fn_ext == '' else f' ({fn_ext.replace(\"_\",\" \").lstrip()})'\n",
    "    title = f'{para_to_plot}: {metric}{title_ext}'\n",
    "    print(f'Plotting {title}...')\n",
    "    \n",
    "    for n, up in enumerate(upgrade_sets.keys(),1):\n",
    "        print(f'    - Group{n}')\n",
    "        \n",
    "        groupi = groups_avg[(groups_avg['metrics']==metric) & \n",
    "                              (groups_avg['upgrade_no'].isin(upgrade_sets[up]))][[\n",
    "            'upgrade_name',para_to_plot]].set_index('upgrade_name').sort_values(by=para_to_plot)\n",
    "        groupi.index.name = up\n",
    "        \n",
    "        ht = len(groupi)\n",
    "        fig, ax = plt.subplots(figsize=(6, 0.3*ht))\n",
    "        groupi.plot.barh(color=upgrade_set_colors[up], legend=False, title=title, ax=ax)\n",
    "        \n",
    "        # For each bar: Place a label ############################\n",
    "        rects = ax.patches\n",
    "        for rect in rects:\n",
    "            # Get X and Y placement of label from rect.\n",
    "            x_value = rect.get_width()\n",
    "            y_value = rect.get_y() + rect.get_height() / 2\n",
    "\n",
    "            # Number of points between bar and label. Change to your liking.\n",
    "            space = 5\n",
    "            # Vertical alignment for positive values\n",
    "            ha = 'left'\n",
    "\n",
    "            # If value of bar is negative: Place label left of bar\n",
    "            if x_value < 0:\n",
    "                # Invert space to place label to the left\n",
    "                space *= -1\n",
    "                # Horizontally align label at right\n",
    "                ha = 'right'\n",
    "\n",
    "            # Use X value as label and format number with one decimal place\n",
    "            label = \"{:.1f}\".format(x_value)\n",
    "\n",
    "            # Create annotation\n",
    "            plt.annotate(\n",
    "                label,                      # Use `label` as label\n",
    "                (x_value, y_value),         # Place label at end of the bar\n",
    "                xytext=(space, 0),          # Horizontally shift label by `space`\n",
    "                textcoords=\"offset points\", # Interpret `xytext` as offset in points\n",
    "                va='center',                # Vertically center label\n",
    "                ha=ha,                      # Horizontally align label differently for\n",
    "                fontsize=8)                 # positive and negative values. \n",
    "            \n",
    "        ax.margins(x=0.2)    \n",
    "        ax.axvline(x=0, linestyle='-', color='gray')\n",
    "        if (metric[-3:]=='eui') & (ax.get_xlim()[0] < -50):\n",
    "            ax.axvline(x=-50, linestyle='--', color='darkred')\n",
    "        \n",
    "        filename = f'upgrades_{iteration}-{para_to_plot}_{metric}{fn_ext}.pdf'\n",
    "        fig.savefig(os.path.join(plot_path2, filename),\n",
    "                    bbox_inches='tight')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.3. plot mean values for Chicago total stock \n",
    "Run cell below to load df for plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_df_for_plot_below_from_file = False # <-----\n",
    "\n",
    "if load_df_for_plot_below_from_file:\n",
    "    NG_rate_multiplier = 1 # 1 or 3 <----- This controls what to plot in both '2.3.1.' and '2.3.2.' plots\n",
    " \n",
    "    if NG_rate_multiplier > 1:\n",
    "        fn_ext = f'_{NG_rate_multiplier}x_gas_prices' # file name extension to add to relevant results\n",
    "    else:\n",
    "        fn_ext = ''\n",
    "    \n",
    "    groups_total = pd.read_csv(os.path.join(result_path,'processed results',f'upgrades_prototype_chicago_total{fn_ext}.csv'),\n",
    "                         header=[0])\n",
    "    \n",
    "    print(f'\"groups_total{fn_ext}\" df loaded from file.')\n",
    "    display(groups_total)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_to_plot = 'Chicago total' # <------\n",
    "\n",
    "N_upgrades = 4\n",
    "upgrade_sets = {\n",
    "    'Packages': [11, 13, 17, 18],\n",
    "}\n",
    "upgrade_set_colors = {\n",
    "    'Packages': 'tab:blue',\n",
    "}\n",
    "\n",
    "# create subfolder for plots:\n",
    "plot_path3 = os.path.join(plot_path, 'sum_values_chicago_total')\n",
    "if not os.path.exists(plot_path3):\n",
    "    os.mkdir(plot_path3)\n",
    "print(f'plot dir: {plot_path3}\\n')\n",
    "\n",
    "if NG_rate_multiplier == 1:  \n",
    "    metrics_to_plot = groups_total['metrics'].unique()\n",
    "else:\n",
    "    metrics_to_plot = ['mean_ann_gas_cost_saving']\n",
    "    \n",
    "for metric in metrics_to_plot:\n",
    "    title_ext = '' if fn_ext == '' else f' ({fn_ext.replace(\"_\",\" \").lstrip()})'\n",
    "    title = f'{para_to_plot} {metric[5:]}{title_ext}'\n",
    "    print(f'Plotting {title}...')\n",
    "    \n",
    "    for n, up in enumerate(upgrade_sets.keys(),1):\n",
    "        print(f'    - Group{n}')\n",
    "        \n",
    "        groupi = groups_total[(groups_total['metrics']==metric) & \n",
    "                              (groups_total['upgrade_no'].isin(upgrade_sets[up]))][[\n",
    "            'upgrade_name',para_to_plot]].set_index('upgrade_name').sort_values(by=para_to_plot)\n",
    "        groupi.index.name = up\n",
    "        \n",
    "        ht = len(groupi)\n",
    "        fig, ax = plt.subplots(figsize=(6, 0.3*ht))\n",
    "        groupi.plot.barh(color=upgrade_set_colors[up], legend=False, title=title, ax=ax)\n",
    "        \n",
    "        # For each bar: Place a label ############################\n",
    "        rects = ax.patches\n",
    "        for rect in rects:\n",
    "            # Get X and Y placement of label from rect.\n",
    "            x_value = rect.get_width()\n",
    "            y_value = rect.get_y() + rect.get_height() / 2\n",
    "\n",
    "            # Number of points between bar and label. Change to your liking.\n",
    "            space = 5\n",
    "            # Vertical alignment for positive values\n",
    "            ha = 'left'\n",
    "\n",
    "            # If value of bar is negative: Place label left of bar\n",
    "            if x_value < 0:\n",
    "                # Invert space to place label to the left\n",
    "                space *= -1\n",
    "                # Horizontally align label at right\n",
    "                ha = 'right'\n",
    "\n",
    "            # Use X value as label and format number with one decimal place\n",
    "            label = \"{:.2E}\".format(x_value)\n",
    "\n",
    "            # Create annotation\n",
    "            plt.annotate(\n",
    "                label,                      # Use `label` as label\n",
    "                (x_value, y_value),         # Place label at end of the bar\n",
    "                xytext=(space, 0),          # Horizontally shift label by `space`\n",
    "                textcoords=\"offset points\", # Interpret `xytext` as offset in points\n",
    "                va='center',                # Vertically center label\n",
    "                ha=ha,                      # Horizontally align label differently for\n",
    "                fontsize=8)                 # positive and negative values.                      \n",
    "                                            \n",
    "        ax.margins(x=0.25)\n",
    "        ax.axvline(x=0, linestyle='-', color='gray')\n",
    "        \n",
    "        filename = f'upgrades_{iteration}-{para_to_plot}_{metric[5:]}{fn_ext}.pdf'\n",
    "        fig.savefig(os.path.join(plot_path3, filename),\n",
    "                    bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.4. plot metrics distribution\n",
    "Run cell below to load df for plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_df_for_plot_below_from_file = False # <-----\n",
    "\n",
    "if load_df_for_plot_below_from_file:\n",
    "    NG_rate_multiplier = 1 # 1 or 3 <----- This controls what to plot in both '2.3.1.' and '2.3.2.' plots\n",
    " \n",
    "    if NG_rate_multiplier > 1:\n",
    "        fn_ext = f'_{NG_rate_multiplier}x_gas_prices' # file name extension to add to relevant results\n",
    "    else:\n",
    "        fn_ext = ''\n",
    "\n",
    "    all_proto_upgrades = pd.read_csv(os.path.join(result_path, 'processed results', 'all_upgrades_by_prototype_combined.csv'))\n",
    "    \n",
    "    print(f'\"all_proto_upgrades{fn_ext}\" df loaded from file.')\n",
    "    N_upgrades = all_proto_upgrades['package_no'].unique().max()\n",
    "    print(f'   total number of packages: {N_upgrades}')\n",
    "    \n",
    "    display(all_proto_upgrades)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### other metrics to consider:\n",
    "# monthly utility bills (gas + elec)\n",
    "# carbon savings (require timeseries results)\n",
    "\n",
    "# create subfolder for plots:\n",
    "plot_path4 = os.path.join(plot_path, 'distribution_by_prototype')\n",
    "if not os.path.exists(plot_path4):\n",
    "    os.mkdir(plot_path4)\n",
    "print(f'plot dir: {plot_path4}\\n')\n",
    "\n",
    "title_ext = '' if fn_ext == '' else f' ({fn_ext.replace(\"_\",\" \").lstrip()})'\n",
    "\n",
    "## modifying payback periods, cap either ends at [100,-100] \n",
    "all_proto_upgrades.loc[(all_proto_upgrades[all_proto_upgrades['simple_payback']>100]).index,\n",
    "                       'simple_payback'] = 100\n",
    "all_proto_upgrades.loc[(all_proto_upgrades[all_proto_upgrades['simple_payback']<-100]).index,\n",
    "                       'simple_payback'] = -100\n",
    "\n",
    "if NG_rate_multiplier == 1:\n",
    "    para_labels = {\n",
    "        'pct_delta_gas_eui': 'Percent change from baseline in gas use intensity (therm/sqft)',\n",
    "        'pct_delta_elec_eui': 'Percent change from baseline in electricity use intensity (kWh/sqft)',\n",
    "        'pct_delta_site_eui': 'Percent change from baseline in site energy use intensity (kBtu/sqft)',\n",
    "        'upgrade_cost': 'Upgrade capital cost ($)',\n",
    "        'ann_kbtu_saved_per_dollar': 'Annual site energy saving per upgrade cost (kBtu/$)',\n",
    "        'ann_energy_cost_saving': f'Annual site energy cost saving{title_ext}',\n",
    "        'ann_metric_ton_co2e_saving': f'Annual carbon emission saving (metric ton CO₂e)',\n",
    "        'simple_payback': f'Simple payback period (yr){title_ext}',\n",
    "    }\n",
    "else:\n",
    "    para_labels = {\n",
    "        'ann_energy_cost_saving': f'Annual site energy cost saving{title_ext}',\n",
    "        'simple_payback': f'Simple payback period (yr){title_ext}',\n",
    "    }\n",
    "\n",
    "N_upgrades=19\n",
    "cols_to_match = list(f'pkg{n:02d}' for n in range(6,N_upgrades+6))\n",
    "\n",
    "for i, para_to_plot in enumerate(para_labels.keys(),1):\n",
    "    \n",
    "    print(f'>> {i}. plotting {para_to_plot}{fn_ext}...')\n",
    "    xmin = all_proto_upgrades[para_to_plot].min(); xmax = all_proto_upgrades[para_to_plot].max()\n",
    "    \n",
    "    fig, axes = plt.subplots(ncols=15, nrows=1, sharex=True, sharey=True, figsize=(30, 6))\n",
    "    for h in range(1,16):\n",
    "        ax = axes[h-1]\n",
    "        p = all_proto_upgrades.query('HousingGroupNo==@h')[['HousingGroupNo','HousingGroupName',\n",
    "                                                            'package_no', para_to_plot]]\n",
    "        lab = f'{p[\"HousingGroupNo\"].iloc[0]}. {p[\"HousingGroupName\"].iloc[0]}'\n",
    "        lab = '\\n'.join([lab[i:i+15] for i in range(0, len(lab), 15)]) # break up long string\n",
    "        p.loc[:,'package_no'] = 'pkg'+p['package_no'].astype(str).str.zfill(2)\n",
    "        p = p.sort_values(by='package_no')\n",
    "        p = p.set_index([p.index, 'package_no'])[\n",
    "            para_to_plot].unstack(level=-1).dropna(\n",
    "            axis=0, how='all')\n",
    "        \n",
    "        ### show all upgrades\n",
    "        for col in set(cols_to_match)-set(p.columns):\n",
    "            p[col] = np.nan\n",
    "        p = p.sort_index(axis=1).reset_index(drop=True)\n",
    "    \n",
    "        if para_to_plot == 'simple_payback':\n",
    "            showmeans = False\n",
    "        else:\n",
    "            showmeans = True\n",
    "            \n",
    "        try:\n",
    "            p.boxplot(ax=ax, vert=False, grid=False, showmeans=showmeans)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        ax.set_title(lab)\n",
    "        if h==1:\n",
    "            ax.set_ylabel('package')\n",
    "        ax.axvline(x=0, linestyle='-.', color='gray')\n",
    "        if (para_to_plot[-3:]=='eui') & (xmin < -50):\n",
    "            ax.axvline(x=-50, linestyle='--', color='darkred')\n",
    "            \n",
    "        ax.set_yticks(range(1, 1+N_upgrades))\n",
    "        ax.set_yticklabels(cols_to_match)\n",
    "        \n",
    "    para_label = para_labels[para_to_plot]\n",
    "    fig.suptitle(para_label, fontsize=20, y=1.03)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    filename = os.path.join(plot_path4, f'{iter_path}-distribution_{para_to_plot}{fn_ext}.pdf')\n",
    "    fig.savefig(filename, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
